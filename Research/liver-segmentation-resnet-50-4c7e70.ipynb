{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **1- Upgrades**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install --upgrade kornia > /dev/null\n!pip install --upgrade fastai > /dev/null","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:13.731737Z","iopub.execute_input":"2022-04-08T08:18:13.732077Z","iopub.status.idle":"2022-04-08T08:18:43.147643Z","shell.execute_reply.started":"2022-04-08T08:18:13.731993Z","shell.execute_reply":"2022-04-08T08:18:43.146786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **2- Imports**","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport cv2\nimport imageio\n\nimport numpy as np \nimport pandas as pd \nimport nibabel as nib\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\nfrom ipywidgets import *\nfrom PIL import Image\nfrom matplotlib.pyplot import figure\n\nfrom fastai.basics import *\nfrom fastai.vision.all import *\nfrom fastai.data.transforms import *","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:43.149952Z","iopub.execute_input":"2022-04-08T08:18:43.150238Z","iopub.status.idle":"2022-04-08T08:18:46.293581Z","shell.execute_reply.started":"2022-04-08T08:18:43.150202Z","shell.execute_reply":"2022-04-08T08:18:46.29278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3- Data Preparation**","metadata":{}},{"cell_type":"code","source":"# Create a meta file for nii files processing\n\nfile_list = []\nfor dirname, _, filenames in os.walk('../input/liver-tumor-segmentation'):\n    for filename in filenames:\n        file_list.append((dirname, filename)) \n\nfor dirname, _, filenames in os.walk('../input/liver-tumor-segmentation-part-2'):\n    for filename in filenames:\n        file_list.append((dirname, filename)) \n\ndf_files = pd.DataFrame(file_list, columns =['dirname', 'filename']) \ndf_files.sort_values(by=['filename'], ascending=True)    ","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:46.294981Z","iopub.execute_input":"2022-04-08T08:18:46.29523Z","iopub.status.idle":"2022-04-08T08:18:46.40475Z","shell.execute_reply.started":"2022-04-08T08:18:46.295196Z","shell.execute_reply":"2022-04-08T08:18:46.404055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map CT scan and label \n\ndf_files[\"mask_dirname\"]  = \"\"\ndf_files[\"mask_filename\"] = \"\"\n\nfor i in range(131):\n    ct = f\"volume-{i}.nii\"\n    mask = f\"segmentation-{i}.nii\"\n    \n    df_files.loc[df_files['filename'] == ct, 'mask_filename'] = mask\n    df_files.loc[df_files['filename'] == ct, 'mask_dirname'] = \"../input/liver-tumor-segmentation/segmentations\"\n\n# drop segment rows\ndf_files = df_files[df_files.mask_filename != ''].sort_values(by=['filename']).reset_index(drop=True) \n\ndf_files","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:46.407099Z","iopub.execute_input":"2022-04-08T08:18:46.407389Z","iopub.status.idle":"2022-04-08T08:18:46.578382Z","shell.execute_reply.started":"2022-04-08T08:18:46.407355Z","shell.execute_reply":"2022-04-08T08:18:46.577434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_nii(filepath):\n    '''\n    Reads .nii file and returns pixel array\n    '''\n    ct_scan = nib.load(filepath)\n    array   = ct_scan.get_fdata()\n    array   = np.rot90(np.array(array))\n    return(array)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:46.579816Z","iopub.execute_input":"2022-04-08T08:18:46.580686Z","iopub.status.idle":"2022-04-08T08:18:46.587408Z","shell.execute_reply.started":"2022-04-08T08:18:46.580641Z","shell.execute_reply":"2022-04-08T08:18:46.585193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read sample\n\nsample = 0\nsample_ct = read_nii(df_files.loc[sample,'dirname']+\"/\"+df_files.loc[sample,'filename'])\nsample_mask = read_nii(df_files.loc[sample,'mask_dirname']+\"/\"+df_files.loc[sample,'mask_filename'])\n\nprint(f'CT Shape:   {sample_ct.shape}\\nMask Shape: {sample_mask.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:46.589367Z","iopub.execute_input":"2022-04-08T08:18:46.589988Z","iopub.status.idle":"2022-04-08T08:18:47.417647Z","shell.execute_reply.started":"2022-04-08T08:18:46.58995Z","shell.execute_reply":"2022-04-08T08:18:47.416874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.amin(sample_ct), np.amax(sample_ct))\nprint(np.amin(sample_mask), np.amax(sample_mask))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:47.419101Z","iopub.execute_input":"2022-04-08T08:18:47.419614Z","iopub.status.idle":"2022-04-08T08:18:47.535322Z","shell.execute_reply.started":"2022-04-08T08:18:47.419558Z","shell.execute_reply":"2022-04-08T08:18:47.534567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess the nii file \n# Source https://docs.fast.ai/medical.imaging\n\ndicom_windows = types.SimpleNamespace(\n    brain=(80,40),\n    subdural=(254,100),\n    stroke=(8,32),\n    brain_bone=(2800,600),\n    brain_soft=(375,40),\n    lungs=(1500,-600),\n    mediastinum=(350,50),\n    abdomen_soft=(400,50),\n    liver=(150,30),\n    spine_soft=(250,50),\n    spine_bone=(1800,400),\n    custom = (200,60)\n)\n\n@patch\ndef windowed(self:Tensor, w, l):\n    px = self.clone()\n    px_min = l - w//2\n    px_max = l + w//2\n    px[px<px_min] = px_min\n    px[px>px_max] = px_max\n    return (px-px_min) / (px_max-px_min)\n\nfigure(figsize=(8, 6), dpi=100)\n\nplt.imshow(tensor(sample_ct[..., 55].astype(np.float32)).windowed(*dicom_windows.liver), cmap=plt.cm.bone);","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:47.536455Z","iopub.execute_input":"2022-04-08T08:18:47.537275Z","iopub.status.idle":"2022-04-08T08:18:47.908561Z","shell.execute_reply.started":"2022-04-08T08:18:47.537235Z","shell.execute_reply":"2022-04-08T08:18:47.907291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sample(array_list, color_map = 'nipy_spectral'):\n    '''\n    Plots and a slice with all available annotations\n    '''\n    fig = plt.figure(figsize=(20,16), dpi=100)\n\n    plt.subplot(1,4,1)\n    plt.imshow(array_list[0], cmap='bone')\n    plt.title('Original Image')\n    plt.axis('off')\n    \n    plt.subplot(1,4,2)\n    plt.imshow(tensor(array_list[0].astype(np.float32)).windowed(*dicom_windows.liver), cmap='bone');\n    plt.title('Windowed Image')\n    plt.axis('off')\n             \n    plt.subplot(1,4,3)\n    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n    plt.title('Mask')\n    plt.axis('off')\n    \n    plt.subplot(1,4,4)\n    plt.imshow(array_list[0], cmap='bone')\n    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n    plt.title('Liver & Mask')\n    plt.axis('off')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:47.909616Z","iopub.execute_input":"2022-04-08T08:18:47.909846Z","iopub.status.idle":"2022-04-08T08:18:47.920155Z","shell.execute_reply.started":"2022-04-08T08:18:47.909818Z","shell.execute_reply":"2022-04-08T08:18:47.919338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = 55\n\nsample_slice = tensor(sample_ct[...,sample].astype(np.float32))\n\nplot_sample([sample_ct[..., sample],\n             sample_mask[..., sample]])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:47.923776Z","iopub.execute_input":"2022-04-08T08:18:47.924132Z","iopub.status.idle":"2022-04-08T08:18:48.441572Z","shell.execute_reply.started":"2022-04-08T08:18:47.924093Z","shell.execute_reply":"2022-04-08T08:18:48.440193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the mask values\nmask = Image.fromarray(sample_mask[...,sample].astype('uint8'), mode=\"L\")\nunique, counts = np.unique(mask, return_counts=True)\nprint(np.array((unique, counts)).T)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:48.442882Z","iopub.execute_input":"2022-04-08T08:18:48.445302Z","iopub.status.idle":"2022-04-08T08:18:48.458321Z","shell.execute_reply.started":"2022-04-08T08:18:48.445262Z","shell.execute_reply":"2022-04-08T08:18:48.457343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing functions\n# Source https://docs.fast.ai/medical.imaging\n\nclass TensorCTScan(TensorImageBW): _show_args = {'cmap':'bone'}\n\n@patch\ndef freqhist_bins(self:Tensor, n_bins=100):\n    \"A function to split the range of pixel values into groups, such that each group has around the same number of pixels\"\n    imsd = self.view(-1).sort()[0]\n    t = torch.cat([tensor([0.001]),\n                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n                   tensor([0.999])])\n    t = (len(imsd)*t).long()\n    return imsd[t].unique()\n    \n@patch\ndef hist_scaled(self:Tensor, brks=None):\n    \"Scales a tensor using `freqhist_bins` to values between 0 and 1\"\n    if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n    if brks is None: brks = self.freqhist_bins()\n    ys = np.linspace(0., 1., len(brks))\n    x = self.numpy().flatten()\n    x = np.interp(x, brks.numpy(), ys)\n    return tensor(x).reshape(self.shape).clamp(0.,1.)\n    \n    \n@patch\ndef to_nchan(x:Tensor, wins, bins=None):\n    res = [x.windowed(*win) for win in wins]\n    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))\n    dim = [0,1][x.dim()==3]\n    return TensorCTScan(torch.stack(res, dim=dim))\n\n@patch\ndef save_jpg(x:(Tensor), path, wins, bins=None, quality=120):\n    fn = Path(path).with_suffix('.jpg')\n    x = (x.to_nchan(wins, bins)*255).byte()\n    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])\n    im.save(fn, quality=quality)\n\n_,axs = subplots(1,1)\n\nsample_slice.save_jpg('test.jpg', [dicom_windows.liver, dicom_windows.custom])\nshow_image(Image.open('test.jpg'), ax=axs[0], figsize=(8, 6))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:48.459923Z","iopub.execute_input":"2022-04-08T08:18:48.460298Z","iopub.status.idle":"2022-04-08T08:18:48.721467Z","shell.execute_reply.started":"2022-04-08T08:18:48.460257Z","shell.execute_reply":"2022-04-08T08:18:48.720465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make custom JPG files for Unet training\n# Total number of 131 nii files contains 67072 slices \n\nGENERATE_JPG_FILES = True\n\nif (GENERATE_JPG_FILES) :\n    \n    path = Path(\".\")\n\n    os.makedirs('train_images',exist_ok=True)\n    os.makedirs('train_masks',exist_ok=True)\n\n    for ii in tqdm(range(0,len(df_files),3)): # take 1/3 nii files for training\n        curr_ct        = read_nii(df_files.loc[ii,'dirname']+\"/\"+df_files.loc[ii,'filename'])\n        curr_mask      = read_nii(df_files.loc[ii,'mask_dirname']+\"/\"+df_files.loc[ii,'mask_filename'])\n        curr_file_name = str(df_files.loc[ii,'filename']).split('.')[0]\n        curr_dim       = curr_ct.shape[2] # 512, 512, curr_dim\n\n        for curr_slice in range(0,curr_dim,2): # export every 2nd slice for training\n            data = tensor(curr_ct[...,curr_slice].astype(np.float32))\n            mask = Image.fromarray(curr_mask[...,curr_slice].astype('uint8'), mode=\"L\")\n            data.save_jpg(f\"train_images/{curr_file_name}_slice_{curr_slice}.jpg\", [dicom_windows.liver,dicom_windows.custom])\n            mask.save(f\"train_masks/{curr_file_name}_slice_{curr_slice}_mask.png\")\nelse:\n    path = Path(\"../input/liver-segmentation-with-fastai-v2\") # read jpg from saved kernel output","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:18:48.726729Z","iopub.execute_input":"2022-04-08T08:18:48.727075Z","iopub.status.idle":"2022-04-08T08:32:42.315554Z","shell.execute_reply.started":"2022-04-08T08:18:48.727032Z","shell.execute_reply":"2022-04-08T08:32:42.314792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3- Model Training**\n### I'm gonna use the ResNet-50 model from [ResNet](https://arxiv.org/pdf/1512.03385.pdf)","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 16\nIMAGE_SIZE = 128\n\ncodes = np.array([\"background\",\"liver\",\"tumor\"])\n    \ndef get_x(fname:Path): return fname\ndef label_func(x): return path/'train_masks'/f'{x.stem}_mask.png'\n\ntfms = [IntToFloatTensor(),Normalize()]\n\ndb = DataBlock(blocks=(ImageBlock(),MaskBlock(codes)),  #codes = {\"Backround\": 0,\"Liver\": 1,\"Tumor\": 2}\n               batch_tfms=tfms,\n               splitter=RandomSplitter(),\n               item_tfms=[Resize(IMAGE_SIZE)],\n               get_items=get_image_files,\n               get_y=label_func)\n\nds = db.datasets(source=path/'train_images')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:32:42.316761Z","iopub.execute_input":"2022-04-08T08:32:42.317607Z","iopub.status.idle":"2022-04-08T08:32:42.461094Z","shell.execute_reply.started":"2022-04-08T08:32:42.317568Z","shell.execute_reply":"2022-04-08T08:32:42.460452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 20\nimgs = [ds[idx][0],ds[idx][1]]\nfig, axs = plt.subplots(1, 2)\n\nfor i,ax in enumerate(axs.flatten()):\n    ax.axis('off')\n    ax.imshow(imgs[i])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:32:42.462506Z","iopub.execute_input":"2022-04-08T08:32:42.462746Z","iopub.status.idle":"2022-04-08T08:32:42.705639Z","shell.execute_reply.started":"2022-04-08T08:32:42.462714Z","shell.execute_reply":"2022-04-08T08:32:42.704969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique, counts = np.unique(array(ds[idx][1]), return_counts=True)\n\nprint( np.array((unique, counts)).T)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:32:42.707072Z","iopub.execute_input":"2022-04-08T08:32:42.707527Z","iopub.status.idle":"2022-04-08T08:32:42.725994Z","shell.execute_reply.started":"2022-04-08T08:32:42.707491Z","shell.execute_reply":"2022-04-08T08:32:42.725331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls = db.dataloaders(path/'train_images', bs = BATCH_SIZE) #, num_workers=0\ndls.show_batch()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:32:42.727306Z","iopub.execute_input":"2022-04-08T08:32:42.727535Z","iopub.status.idle":"2022-04-08T08:32:47.193521Z","shell.execute_reply.started":"2022-04-08T08:32:42.727503Z","shell.execute_reply":"2022-04-08T08:32:47.192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def foreground_acc(inp, targ, bkg_idx=0, axis=1):  # exclude a background from metric\n    \"Computes non-background accuracy for multiclass segmentation\"\n    targ = targ.squeeze(1)\n    mask = targ != bkg_idx\n    return (inp.argmax(dim=axis)[mask]==targ[mask]).float().mean() \n\ndef cust_foreground_acc(inp, targ):  # # include a background into the metric\n    return foreground_acc(inp=inp, targ=targ, bkg_idx=3, axis=1) # 3 is a dummy value to include the background which is 0","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:32:47.194908Z","iopub.execute_input":"2022-04-08T08:32:47.195345Z","iopub.status.idle":"2022-04-08T08:32:47.202666Z","shell.execute_reply.started":"2022-04-08T08:32:47.195311Z","shell.execute_reply":"2022-04-08T08:32:47.201893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn = unet_learner(dls,\n                     resnet50,\n                     loss_func=CrossEntropyLossFlat(axis=1),\n                     metrics=[foreground_acc, cust_foreground_acc]) ","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:32:47.204161Z","iopub.execute_input":"2022-04-08T08:32:47.204729Z","iopub.status.idle":"2022-04-08T08:33:00.141255Z","shell.execute_reply.started":"2022-04-08T08:32:47.204687Z","shell.execute_reply":"2022-04-08T08:33:00.140452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.fine_tune(5, wd=0.1, cbs=SaveModelCallback() )","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:33:00.142725Z","iopub.execute_input":"2022-04-08T08:33:00.14298Z","iopub.status.idle":"2022-04-08T09:08:45.774591Z","shell.execute_reply.started":"2022-04-08T08:33:00.142946Z","shell.execute_reply":"2022-04-08T09:08:45.773705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.show_results()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T09:08:45.777623Z","iopub.execute_input":"2022-04-08T09:08:45.777922Z","iopub.status.idle":"2022-04-08T09:08:47.503589Z","shell.execute_reply.started":"2022-04-08T09:08:45.77788Z","shell.execute_reply":"2022-04-08T09:08:47.500647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model\nlearn.export(path/f'Liver_segmentation')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T09:08:47.505069Z","iopub.execute_input":"2022-04-08T09:08:47.505952Z","iopub.status.idle":"2022-04-08T09:08:52.062718Z","shell.execute_reply.started":"2022-04-08T09:08:47.50591Z","shell.execute_reply":"2022-04-08T09:08:52.06178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **4- Testing the Model**","metadata":{}},{"cell_type":"code","source":"# Load saved model\nif (GENERATE_JPG_FILES) :\n    \n    tfms = [Resize(IMAGE_SIZE), IntToFloatTensor(),Normalize()]\n    learn0 = load_learner(path/f'Liver_segmentation',cpu=False )\n    learn0.dls.transform = tfms","metadata":{"execution":{"iopub.status.busy":"2022-04-08T09:08:52.067821Z","iopub.execute_input":"2022-04-08T09:08:52.070372Z","iopub.status.idle":"2022-04-08T09:08:53.562968Z","shell.execute_reply.started":"2022-04-08T09:08:52.070318Z","shell.execute_reply":"2022-04-08T09:08:53.562191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def nii_tfm(fn,wins): \n\n    test_nii  = read_nii(fn)\n    curr_dim  = test_nii.shape[2] # 512, 512, curr_dim\n    slices = []\n    \n    for curr_slice in range(curr_dim):\n        data = tensor(test_nii[...,curr_slice].astype(np.float32))\n        data = (data.to_nchan(wins)*255).byte()\n        slices.append(TensorImage(data))\n                      \n    return slices ","metadata":{"execution":{"iopub.status.busy":"2022-04-08T09:08:53.565521Z","iopub.execute_input":"2022-04-08T09:08:53.565985Z","iopub.status.idle":"2022-04-08T09:08:53.572948Z","shell.execute_reply.started":"2022-04-08T09:08:53.565944Z","shell.execute_reply":"2022-04-08T09:08:53.572083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tst = 20\n\ntest_nii   = read_nii(df_files.loc[tst,'dirname']+\"/\"+df_files.loc[tst,'filename'])\ntest_mask  = read_nii(df_files.loc[tst,'mask_dirname']+\"/\"+df_files.loc[tst,'mask_filename'])\nprint(test_nii.shape)\n\ntest_slice_idx = 500\n\nsample_slice = tensor(test_nii[...,test_slice_idx].astype(np.float32))\n\nplot_sample([test_nii[...,test_slice_idx], test_mask[...,test_slice_idx]])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T09:08:53.574267Z","iopub.execute_input":"2022-04-08T09:08:53.574626Z","iopub.status.idle":"2022-04-08T09:09:13.413089Z","shell.execute_reply.started":"2022-04-08T09:08:53.574589Z","shell.execute_reply":"2022-04-08T09:09:13.412092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare a nii test file for prediction \n\ntest_files = nii_tfm(df_files.loc[tst,'dirname']+\"/\"+df_files.loc[tst,'filename'],[dicom_windows.liver, dicom_windows.custom])\nprint(\"Number of test slices: \", len(test_files))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T09:09:13.414764Z","iopub.execute_input":"2022-04-08T09:09:13.415098Z","iopub.status.idle":"2022-04-08T09:09:52.137933Z","shell.execute_reply.started":"2022-04-08T09:09:13.415063Z","shell.execute_reply":"2022-04-08T09:09:52.137166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check an input for a test file\nshow_image(test_files[test_slice_idx])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T09:09:52.139282Z","iopub.execute_input":"2022-04-08T09:09:52.140071Z","iopub.status.idle":"2022-04-08T09:09:52.34867Z","shell.execute_reply.started":"2022-04-08T09:09:52.14003Z","shell.execute_reply":"2022-04-08T09:09:52.348029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get predictions for a Test file\n\ntest_dl = learn0.dls.test_dl(test_files)\npreds, y = learn0.get_preds(dl=test_dl)\n\npredicted_mask = np.argmax(preds, axis=1)\n\nplt.imshow(predicted_mask[test_slice_idx])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T09:09:52.352481Z","iopub.execute_input":"2022-04-08T09:09:52.353177Z","iopub.status.idle":"2022-04-08T09:10:08.510974Z","shell.execute_reply.started":"2022-04-08T09:09:52.353118Z","shell.execute_reply":"2022-04-08T09:10:08.510061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-----\n# **5- Conclusion**\n### If you compare the predicted mask with the previous image, you'll see that the model performed quite good.","metadata":{}}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}