{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d61b9bb4-a7e9-47d0-840b-4aeced7cca86","_uuid":"4346bde5-e04b-4836-b532-56cd4461c106","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:28.472795Z","iopub.status.busy":"2023-09-17T06:01:28.472447Z","iopub.status.idle":"2023-09-17T06:01:31.894822Z","shell.execute_reply":"2023-09-17T06:01:31.893961Z","shell.execute_reply.started":"2023-09-17T06:01:28.472706Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import os\n","import glob\n","import cv2\n","import imageio\n","\n","import numpy as np \n","import pandas as pd \n","import nibabel as nib\n","import matplotlib.pyplot as plt\n","\n","from tqdm.notebook import tqdm\n","from ipywidgets import *\n","from PIL import Image\n","from matplotlib.pyplot import figure\n","\n","from fastai.basics import *\n","from fastai.vision.all import *\n","from fastai.data.transforms import *"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c410ed90-a924-470a-9aad-274fcbff2583","_uuid":"8606b1d4-09f8-48eb-a6c7-828375856099","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:31.896924Z","iopub.status.busy":"2023-09-17T06:01:31.896645Z","iopub.status.idle":"2023-09-17T06:01:32.070764Z","shell.execute_reply":"2023-09-17T06:01:32.069893Z","shell.execute_reply.started":"2023-09-17T06:01:31.896887Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Create a meta file for nii files processing\n","\n","file_list = []\n","for dirname, _, filenames in os.walk('../input/liver-tumor-segmentation'):\n","    for filename in filenames:\n","        file_list.append((dirname, filename)) \n","\n","for dirname, _, filenames in os.walk('../input/liver-tumor-segmentation-part-2'):\n","    for filename in filenames:\n","        file_list.append((dirname, filename)) \n","\n","df_files = pd.DataFrame(file_list, columns =['dirname', 'filename']) \n","df_files.sort_values(by=['filename'], ascending=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06c308e2-f696-45c1-863c-432eb284a106","_uuid":"5fda5cd9-2fb6-4514-bb59-bc668ab30449","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:32.072705Z","iopub.status.busy":"2023-09-17T06:01:32.072399Z","iopub.status.idle":"2023-09-17T06:01:32.262964Z","shell.execute_reply":"2023-09-17T06:01:32.262190Z","shell.execute_reply.started":"2023-09-17T06:01:32.072666Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Map CT scan and label \n","\n","df_files[\"mask_dirname\"]  = \"\"\n","df_files[\"mask_filename\"] = \"\"\n","\n","for i in range(131):\n","    ct = f\"volume-{i}.nii\"\n","    mask = f\"segmentation-{i}.nii\"\n","    \n","    df_files.loc[df_files['filename'] == ct, 'mask_filename'] = mask\n","    df_files.loc[df_files['filename'] == ct, 'mask_dirname'] = \"../input/liver-tumor-segmentation/segmentations\"\n","\n","# drop segment rows\n","df_files = df_files[df_files.mask_filename != ''].sort_values(by=['filename']).reset_index(drop=True) \n","\n","df_files"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6c62bf3-912b-4b6a-80ea-62977f633832","_uuid":"b1778542-a2c7-43bf-b62a-2565c19d21b4","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:32.269603Z","iopub.status.busy":"2023-09-17T06:01:32.269175Z","iopub.status.idle":"2023-09-17T06:01:32.276770Z","shell.execute_reply":"2023-09-17T06:01:32.275190Z","shell.execute_reply.started":"2023-09-17T06:01:32.269553Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def read_nii(filepath):\n","    '''\n","    Reads .nii file and returns pixel array\n","    '''\n","    ct_scan = nib.load(filepath)\n","    array   = ct_scan.get_fdata()\n","    array   = np.rot90(np.array(array))\n","    return(array)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dea7ebea-ecfb-4246-a573-24aeb483319d","_uuid":"dc593515-da28-435a-a8de-d967b7543424","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:32.278692Z","iopub.status.busy":"2023-09-17T06:01:32.278367Z","iopub.status.idle":"2023-09-17T06:01:33.357544Z","shell.execute_reply":"2023-09-17T06:01:33.356749Z","shell.execute_reply.started":"2023-09-17T06:01:32.278653Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Read sample\n","\n","sample = 0\n","sample_ct = read_nii(df_files.loc[sample,'dirname']+\"/\"+df_files.loc[sample,'filename'])\n","sample_mask = read_nii(df_files.loc[sample,'mask_dirname']+\"/\"+df_files.loc[sample,'mask_filename'])\n","\n","print(f'CT Shape:   {sample_ct.shape}\\nMask Shape: {sample_mask.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a28dcc6e-42c9-49ba-96a3-8222a42c77cc","_uuid":"db79a33f-9380-4ecf-952f-d21558743e90","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:33.359597Z","iopub.status.busy":"2023-09-17T06:01:33.358811Z","iopub.status.idle":"2023-09-17T06:01:33.452182Z","shell.execute_reply":"2023-09-17T06:01:33.451290Z","shell.execute_reply.started":"2023-09-17T06:01:33.359557Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["print(np.amin(sample_ct), np.amax(sample_ct))\n","print(np.amin(sample_mask), np.amax(sample_mask))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c49258a-80a1-4077-8b18-5a58eed588d1","_uuid":"5aaa1f2b-f870-45ca-9048-145882b13a69","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:33.453965Z","iopub.status.busy":"2023-09-17T06:01:33.453628Z","iopub.status.idle":"2023-09-17T06:01:33.829644Z","shell.execute_reply":"2023-09-17T06:01:33.828227Z","shell.execute_reply.started":"2023-09-17T06:01:33.453927Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["dicom_windows = types.SimpleNamespace(\n","    brain=(80,40),\n","    subdural=(254,100),\n","    stroke=(8,32),\n","    brain_bone=(2800,600),\n","    brain_soft=(375,40),\n","    lungs=(1500,-600),\n","    mediastinum=(350,50),\n","    abdomen_soft=(400,50),\n","    liver=(150,30),\n","    spine_soft=(250,50),\n","    spine_bone=(1800,400),\n","    custom = (200,60)\n",")\n","\n","@patch\n","def windowed(self:Tensor, w, l):\n","    px = self.clone()\n","    px_min = l - w//2\n","    px_max = l + w//2\n","    px[px<px_min] = px_min\n","    px[px>px_max] = px_max\n","    return (px-px_min) / (px_max-px_min)\n","\n","figure(figsize=(8, 6), dpi=100)\n","\n","plt.imshow(tensor(sample_ct[..., 55].astype(np.float32)).windowed(*dicom_windows.liver), cmap=plt.cm.bone);"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49eb151d-60b3-46a6-8dfb-ebeee0fcfd80","_uuid":"7de6c43e-cc13-4807-9968-b3fc15d4a044","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:33.830925Z","iopub.status.busy":"2023-09-17T06:01:33.830706Z","iopub.status.idle":"2023-09-17T06:01:33.843051Z","shell.execute_reply":"2023-09-17T06:01:33.842360Z","shell.execute_reply.started":"2023-09-17T06:01:33.830895Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def plot_sample(array_list, color_map = 'nipy_spectral'):\n","    '''Plots and a slice with all available annotations'''\n","    fig = plt.figure(figsize=(20,16), dpi=100)\n","\n","    plt.subplot(1,4,1)\n","    plt.imshow(array_list[0], cmap='bone')\n","    plt.title('Original Image')\n","    plt.axis('off')\n","    \n","    plt.subplot(1,4,2)\n","    plt.imshow(tensor(array_list[0].astype(np.float32)).windowed(*dicom_windows.liver), cmap='bone');\n","    plt.title('Windowed Image')\n","    plt.axis('off')\n","             \n","    plt.subplot(1,4,3)\n","    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n","    plt.title('Mask')\n","    plt.axis('off')\n","    \n","    plt.subplot(1,4,4)\n","    plt.imshow(array_list[0], cmap='bone')\n","    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n","    plt.title('Liver & Mask')\n","    plt.axis('off')\n","    \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f633c69-3e06-4f54-b02c-b6ad3d50090a","_uuid":"99b2eb7a-80eb-4ecd-bb2b-665cf091ad9b","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:33.845133Z","iopub.status.busy":"2023-09-17T06:01:33.844646Z","iopub.status.idle":"2023-09-17T06:01:34.383680Z","shell.execute_reply":"2023-09-17T06:01:34.382268Z","shell.execute_reply.started":"2023-09-17T06:01:33.845095Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["sample = 55\n","\n","sample_slice = tensor(sample_ct[...,sample].astype(np.float32))\n","\n","plot_sample([sample_ct[..., sample],\n","             sample_mask[..., sample]])"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50871a8d-265d-43a8-bbfb-23602f531545","_uuid":"2ec2b037-d747-469e-aa58-a960c405fb98","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:34.387412Z","iopub.status.busy":"2023-09-17T06:01:34.386595Z","iopub.status.idle":"2023-09-17T06:01:34.400116Z","shell.execute_reply":"2023-09-17T06:01:34.399183Z","shell.execute_reply.started":"2023-09-17T06:01:34.387371Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Check the mask values\n","mask = Image.fromarray(sample_mask[...,sample].astype('uint8'), mode=\"L\")\n","unique, counts = np.unique(mask, return_counts=True)\n","print(np.array((unique, counts)).T)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2abb6ca5-cd68-4161-84b8-6bee151b3b71","_uuid":"9272e8f6-d7cb-4dd2-bb88-74631049b5dd","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:34.401989Z","iopub.status.busy":"2023-09-17T06:01:34.401396Z","iopub.status.idle":"2023-09-17T06:01:34.671870Z","shell.execute_reply":"2023-09-17T06:01:34.670743Z","shell.execute_reply.started":"2023-09-17T06:01:34.401951Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","\n","class TensorCTScan(TensorImageBW): _show_args = {'cmap':'bone'}\n","\n","@patch\n","def freqhist_bins(self:Tensor, n_bins=100):\n","    \"A function to split the range of pixel values into groups, such that each group has around the same number of pixels\"\n","    imsd = self.view(-1).sort()[0]\n","    t = torch.cat([tensor([0.001]),\n","                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n","                   tensor([0.999])])\n","    t = (len(imsd)*t).long()\n","    return imsd[t].unique()\n","    \n","@patch\n","def hist_scaled(self:Tensor, brks=None):\n","    \"Scales a tensor using `freqhist_bins` to values between 0 and 1\"\n","    if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n","    if brks is None: brks = self.freqhist_bins()\n","    ys = np.linspace(0., 1., len(brks))\n","    x = self.numpy().flatten()\n","    x = np.interp(x, brks.numpy(), ys)\n","    return tensor(x).reshape(self.shape).clamp(0.,1.)\n","    \n","    \n","@patch\n","def to_nchan(x:Tensor, wins, bins=None):\n","    res = [x.windowed(*win) for win in wins]\n","    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))\n","    dim = [0,1][x.dim()==3]\n","    return TensorCTScan(torch.stack(res, dim=dim))\n","\n","@patch\n","def save_jpg(x:(Tensor), path, wins, bins=None, quality=120):\n","    fn = Path(path).with_suffix('.jpg')\n","    x = (x.to_nchan(wins, bins)*255).byte()\n","    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])\n","    im.save(fn, quality=quality)\n","\n","_,axs = subplots(1,1)\n","\n","sample_slice.save_jpg('test.jpg', [dicom_windows.liver, dicom_windows.custom])\n","show_image(Image.open('test.jpg'), ax=axs[0], figsize=(8, 6))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51d78768-2b1b-42ea-9c67-e440117d1ce8","_uuid":"6262086a-fe6d-4bb9-9636-23a1824cc789","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:01:34.674280Z","iopub.status.busy":"2023-09-17T06:01:34.673516Z","iopub.status.idle":"2023-09-17T06:20:19.379499Z","shell.execute_reply":"2023-09-17T06:20:19.378697Z","shell.execute_reply.started":"2023-09-17T06:01:34.674220Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","GENERATE_JPG_FILES = True\n","\n","if (GENERATE_JPG_FILES) :\n","    \n","    path = Path(\".\")\n","\n","    os.makedirs('train_images',exist_ok=True)\n","    os.makedirs('train_masks',exist_ok=True)\n","\n","    for ii in tqdm(range(0,len(df_files),3)): # take 1/3 nii files for training\n","        curr_ct        = read_nii(df_files.loc[ii,'dirname']+\"/\"+df_files.loc[ii,'filename'])\n","        curr_mask      = read_nii(df_files.loc[ii,'mask_dirname']+\"/\"+df_files.loc[ii,'mask_filename'])\n","        curr_file_name = str(df_files.loc[ii,'filename']).split('.')[0]\n","        curr_dim       = curr_ct.shape[2] # 512, 512, curr_dim\n","\n","        for curr_slice in range(0,curr_dim,2): # export every 2nd slice for training\n","            data = tensor(curr_ct[...,curr_slice].astype(np.float32))\n","            mask = tensor(curr_mask[...,curr_slice].astype(np.float32))\n","            data.save_jpg(f\"train_images/{curr_file_name}_slice_{curr_slice}.jpg\", [dicom_windows.liver,dicom_windows.custom])\n","            mask.save_jpg(f\"train_masks/{curr_file_name}_slice_{curr_slice}_mask.jpg\", [dicom_windows.liver,dicom_windows.custom])\n","else:\n","    path = Path(\"../input/liver-segmentation-with-fastai-v2\") # read jpg from saved kernel output"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e73614ba-68c1-4773-ab35-f5e9fdb94768","_uuid":"9a945edb-6676-478d-ae07-a9192161ce2d","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:20:19.381711Z","iopub.status.busy":"2023-09-17T06:20:19.380842Z","iopub.status.idle":"2023-09-17T06:20:19.426867Z","shell.execute_reply":"2023-09-17T06:20:19.426132Z","shell.execute_reply.started":"2023-09-17T06:20:19.381668Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Create a meta file for nii files processing\n","file_list = []\n","mask_list = []\n","for dirname, _, filenames in os.walk('/kaggle/working/train_images'):\n","    for filename in filenames:\n","        file_list.append(filename) \n","\n","for dirname, _, filenames in os.walk('/kaggle/working/train_masks'):\n","    for filename in filenames:\n","        mask_list.append(filename) \n","\n","files = pd.DataFrame({\"train\": file_list, \"mask\": mask_list})"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a5f7bea-4128-4b75-b357-de8faa5afb3c","_uuid":"775d4f56-4ab0-4053-95fb-25dc164a0fc1","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:20:19.428896Z","iopub.status.busy":"2023-09-17T06:20:19.428361Z","iopub.status.idle":"2023-09-17T06:20:19.543466Z","shell.execute_reply":"2023-09-17T06:20:19.542649Z","shell.execute_reply.started":"2023-09-17T06:20:19.428857Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["filename = []\n","for i in range(len(files)):\n","    root = \"/kaggle/working/train_images\"\n","    path = os.path.join(root, files[\"train\"][i])\n","    filename.append(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3022b467-5475-46da-8b1c-2992709ebaf7","_uuid":"f8c54ab0-6ce2-4d52-8fd3-928dbad523f6","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:20:19.545247Z","iopub.status.busy":"2023-09-17T06:20:19.544957Z","iopub.status.idle":"2023-09-17T06:20:19.656987Z","shell.execute_reply":"2023-09-17T06:20:19.656251Z","shell.execute_reply.started":"2023-09-17T06:20:19.545197Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["mask = []\n","for i in range(len(files)):\n","    root = \"/kaggle/working/train_masks\"\n","    path = os.path.join(root, files[\"train\"][i])\n","    mask.append(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e4e6e95-4483-41d8-a16e-ab72db6abcb2","_uuid":"4d7da4b0-f291-4a91-b3da-2072c2fdaae1","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:20:19.658409Z","iopub.status.busy":"2023-09-17T06:20:19.658129Z","iopub.status.idle":"2023-09-17T06:20:19.666062Z","shell.execute_reply":"2023-09-17T06:20:19.665218Z","shell.execute_reply.started":"2023-09-17T06:20:19.658374Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["df = pd.DataFrame(data={\"filename\": filename, 'mask' : mask})"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1536f92-c29c-49db-8da4-63297759f20a","_uuid":"b052fd7e-85c9-4352-9e06-cba9c3b2c792","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:20:19.667165Z","iopub.status.busy":"2023-09-17T06:20:19.666942Z","iopub.status.idle":"2023-09-17T06:20:19.698755Z","shell.execute_reply":"2023-09-17T06:20:19.697967Z","shell.execute_reply.started":"2023-09-17T06:20:19.667138Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["df['mask'] = df['mask'].str.split(\".\").str[0] + \"_mask.jpg\""]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"55387f04-ba38-45fe-acc4-fa14d2f66194","_uuid":"f37c67bd-2347-4ca5-bbd6-8f4286ce0e3e","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:20:19.700285Z","iopub.status.busy":"2023-09-17T06:20:19.700008Z","iopub.status.idle":"2023-09-17T06:20:19.960657Z","shell.execute_reply":"2023-09-17T06:20:19.959932Z","shell.execute_reply.started":"2023-09-17T06:20:19.700249Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","\n","image= cv2.imread(df['mask'][5])\n","print(image.shape)\n","plt.imshow(image)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49f6adf8-dd0c-43bf-8123-d01a27809d0c","_uuid":"8a49b046-975a-4332-adcd-8c7ba044edde","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:20:19.962618Z","iopub.status.busy":"2023-09-17T06:20:19.961944Z","iopub.status.idle":"2023-09-17T06:20:19.976939Z","shell.execute_reply":"2023-09-17T06:20:19.975987Z","shell.execute_reply.started":"2023-09-17T06:20:19.962586Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","df_train, df_test = train_test_split(df,test_size = 0.1, random_state = 42)\n","df_train, df_val = train_test_split(df_train,test_size = 0.2, random_state = 42)\n","print(df_train.values.shape)\n","print(df_val.values.shape)\n","print(df_test.values.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bf4ce016-6e2f-4f94-a9be-78fea40f0230","_uuid":"c32a77b5-1b39-4c75-b6ce-88848e2aee74","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:20:19.979058Z","iopub.status.busy":"2023-09-17T06:20:19.978783Z","iopub.status.idle":"2023-09-17T06:20:25.354741Z","shell.execute_reply":"2023-09-17T06:20:25.353921Z","shell.execute_reply.started":"2023-09-17T06:20:19.979028Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from __future__ import print_function\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np \n","import os\n","import glob\n","import skimage.io as io\n","import skimage.transform as trans\n","import sys\n","# from mode.config import *\n","np.set_printoptions(threshold=sys.maxsize, precision=5, suppress=True)\n","\n","tumor = [120,0,0]\n","liver = [0,255,0]\n","Unlabelled = [0,0,0]\n","\n","COLOR_DICT = np.array([ tumor, liver, Unlabelled])\n","class_name = [ 'tumor', 'liver', 'None']  # You must define by yourself\n","\n","color = 'grayscale'\n","\n","num_classes = 3 # include cat, dog and None.\n","# num_of_test_img = arg.img_num\n","\n","test_img_size = 256 * 256\n","\n","img_size = (256,256)\n","\n","\n","\n","def adjustData(img,mask,flag_multi_class,num_class):\n","    if(flag_multi_class):\n","        img = img / 255.\n","        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n","        mask[(mask!=0.)&(mask!=255.)&(mask!=128.)] = 0.\n","        new_mask = np.zeros(mask.shape + (num_class,))\n","        new_mask[mask == 255.,   0] = 1\n","        new_mask[mask == 128.,   1] = 1\n","        new_mask[mask == 0.,   2] = 1\n","        mask = new_mask\n","\n","    elif(np.max(img) > 1):\n","        img = img / 255.\n","        mask = mask /255.\n","        mask[mask > 0.5] = 1\n","        mask[mask <= 0.5] = 0\n","    return (img,mask)\n","\n","\n","\n","def trainGenerator( batch_size, dataframe, aug_dict, image_color_mode = \"grayscale\",\n","                    mask_color_mode = \"grayscale\", image_save_prefix  = \"image\", mask_save_prefix  = \"mask\",\n","                    flag_multi_class = True, num_class = num_classes , save_to_dir = None, target_size = img_size, seed = 1):\n","    image_datagen = ImageDataGenerator(**aug_dict)\n","    mask_datagen = ImageDataGenerator(**aug_dict)\n","    image_generator = image_datagen.flow_from_dataframe(\n","        dataframe,\n","        x_col = \"filename\",\n","        class_mode = None,\n","        color_mode = image_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = image_save_prefix,\n","        seed = seed)\n","    mask_generator = mask_datagen.flow_from_dataframe(\n","        dataframe,\n","        x_col = \"mask\",\n","        class_mode = None,\n","        color_mode = mask_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = mask_save_prefix,\n","        seed = seed)\n","#     print('classes:',image_generator.class_indices, mask_generator.class_indices)\n","    train_generator = zip(image_generator, mask_generator)\n","    for (img,mask) in train_generator:\n","        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n","        yield (img,mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9dace59-f728-4b30-9530-a9f9cda55b0a","_uuid":"0477a3c4-68a6-4e3e-9004-d17135e45dde","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T06:20:25.356566Z","iopub.status.busy":"2023-09-17T06:20:25.356216Z","iopub.status.idle":"2023-09-17T06:20:25.680091Z","shell.execute_reply":"2023-09-17T06:20:25.679301Z","shell.execute_reply.started":"2023-09-17T06:20:25.356526Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import numpy as np \n","import os\n","import skimage.io as io\n","import skimage.transform as trans\n","import numpy as np\n","# from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras import backend as keras\n","# from mode.config import *\n","# from tensorflow.contrib.opt import AdamWOptimizer\n","from tensorflow.python.keras.optimizers import TFOptimizer\n","from tensorflow.keras import backend as K\n","from keras.models import Model\n","\n","img_size = (256,256,1) # 256 * 256 grayscale img with 1 channel\n","\n","dr_rate = 0.6 # never mind\n","leakyrelu_alpha = 0.3\n","\n","def unet(pretrained_weights = None,input_size = img_size):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = LeakyReLU(alpha=leakyrelu_alpha)(conv1)\n","    #conv1 = Dropout(dr_rate)(conv1) ###\n","    conv1 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    conv1 = BatchNormalization()(conv1)    \n","    conv1 = LeakyReLU(alpha=leakyrelu_alpha)(conv1)\n","    #conv1 = Dropout(dr_rate)(conv1) ###\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    #pool1 = Dropout(dr_rate)(pool1) ### \n","    \n","    conv2 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = LeakyReLU(alpha=leakyrelu_alpha)(conv2)\n","    #conv2 = Dropout(dr_rate)(conv2)###\n","    conv2 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = LeakyReLU(alpha=leakyrelu_alpha)(conv2)    \n","    #conv2 = Dropout(dr_rate)(conv2)###    \n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    \n","    conv3 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = LeakyReLU(alpha=leakyrelu_alpha)(conv3)\n","    #conv3 = Dropout(dr_rate)(conv3) ###\n","    conv3 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = LeakyReLU(alpha=leakyrelu_alpha)(conv3)\n","    #conv3 = Dropout(dr_rate)(conv3) ###\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    \n","    conv4 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = LeakyReLU(alpha=leakyrelu_alpha)(conv4)    \n","    #conv4 = Dropout(dr_rate)(conv4) ###\n","    conv4 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = LeakyReLU(alpha=leakyrelu_alpha)(conv4)\n","    drop4 = Dropout(dr_rate)(conv4) ###\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)    \n","\n","    conv5 = Conv2D(1024, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = BatchNormalization()(conv5)    \n","    conv5 = LeakyReLU(alpha=leakyrelu_alpha)(conv5)\n","    #conv5 = Dropout(dr_rate)(conv5) ###\n","    conv5 = Conv2D(1024, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    drop5 = LeakyReLU(alpha=leakyrelu_alpha)(conv5)\n","    #drop5 = Dropout(dr_rate)(conv5) ###\n","\n","    up6 = Conv2D(512, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    up6 = LeakyReLU(alpha=leakyrelu_alpha)(up6)\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = LeakyReLU(alpha=leakyrelu_alpha)(conv6)\n","    #conv6 = Dropout(dr_rate)(conv6) ###\n","    conv6 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = LeakyReLU(alpha=leakyrelu_alpha)(conv6)    \n","    #conv6 = Dropout(dr_rate)(conv6) ###   \n","\n","    up7 = Conv2D(256, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    up7 = BatchNormalization()(up7)    \n","    up7 = LeakyReLU(alpha=leakyrelu_alpha)(up7)\n","    up7 = Dropout(dr_rate)(up7) ###\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = BatchNormalization()(conv7)    \n","    conv7 = LeakyReLU(alpha=leakyrelu_alpha)(conv7)    \n","    #conv7 = Dropout(dr_rate)(conv7) ###\n","    conv7 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = LeakyReLU(alpha=leakyrelu_alpha)(conv7)\n","    #conv7 = Dropout(dr_rate)(conv7) ###   \n","\n","    up8 = Conv2D(128, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    up8 = BatchNormalization()(up8)\n","    up8 = LeakyReLU(alpha=0.3)(up8)\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = BatchNormalization()(conv8)\n","    conv8 = LeakyReLU(alpha=0.3)(conv8)\n","    #conv8 = Dropout(dr_rate)(conv8) ###\n","    conv8 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","    conv8 = BatchNormalization()(conv8)    \n","    conv8 = LeakyReLU(alpha=0.3)(conv8)    \n","    #conv8 = Dropout(dr_rate)(conv8) ###    \n","\n","    up9 = Conv2D(64, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    up9 = BatchNormalization()(up9)\n","    up9 = LeakyReLU(alpha=leakyrelu_alpha)(up9)\n","    up9 = Dropout(dr_rate)(up9) ###\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n","    #conv9 = Dropout(dr_rate)(conv9) ###\n","    conv9 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = BatchNormalization()(conv9)    \n","    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n","    #conv9 = Dropout(dr_rate)(conv9) ###\n","    conv9 = Conv2D(2, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n","    #conv9 = Dropout(dr_rate)(conv9) ###\n","\n","    conv10 = Conv2D(3, 1, activation = 'softmax')(conv9)\n","    model = Model(inputs = inputs, outputs = conv10)   \n","    model.compile(optimizer = Adam(lr = 3e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","    \n","    #model.summary()\n","\n","    if(pretrained_weights):\n","    \tmodel.load_weights(pretrained_weights)\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"534efb85-afcc-4376-82f5-194d76521889","_uuid":"b3720f5d-8069-47c2-a020-4e96c75fcce4","collapsed":false,"execution":{"iopub.execute_input":"2023-09-17T07:07:51.705129Z","iopub.status.busy":"2023-09-17T07:07:51.704772Z","iopub.status.idle":"2023-09-17T07:07:57.648997Z","shell.execute_reply":"2023-09-17T07:07:57.647972Z","shell.execute_reply.started":"2023-09-17T07:07:51.705028Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import os\n","import os.path\n","# from model import *\n","# from data import *\n","from keras.models import load_model\n","from keras.callbacks import History\n","import tensorflow as tf\n","import matplotlib.pyplot as plt \n","from keras import backend as K\n","# from mode.config import *\n","# from csvrecord import * \n","from pathlib import Path\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n","from keras.layers import LeakyReLU\n","from tensorflow.keras.optimizers import Adam\n","\n","#from sklearn.model_selection import train_test_split\n","\n","#df_train, df_val = train_test_split(df, test_size=0.2, random_state=42)\n","\n","data_gen_args = dict()\n","\n","myGene = trainGenerator(12, df_train, data_gen_args, save_to_dir = None)\n","valGene = trainGenerator(12, df_val, data_gen_args, save_to_dir=None)\n","\n","model = unet()\n","# model_checkpoint = ModelCheckpoint(model_name, monitor='loss',verbose=1, save_best_only=True)\n","#history = model.fit_generator(myGene, steps_per_epoch=len(df_val)/32, epochs=50)\n","history = model.fit_generator(myGene, steps_per_epoch=len(df_val)/32, epochs=5, validation_data=valGene, validation_steps=len(df_val)/32)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed6ea501-18c9-4c36-bcca-bcf2a7e46f29","_uuid":"76d9f5f9-1943-40a7-be99-bcdb9551f8ee","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
