{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport cv2\nimport imageio\n\nimport numpy as np \nimport pandas as pd \nimport nibabel as nib\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\nfrom ipywidgets import *\nfrom PIL import Image\nfrom matplotlib.pyplot import figure\n\nfrom fastai.basics import *\nfrom fastai.vision.all import *\nfrom fastai.data.transforms import *","metadata":{"_uuid":"4346bde5-e04b-4836-b532-56cd4461c106","_cell_guid":"d61b9bb4-a7e9-47d0-840b-4aeced7cca86","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:28.472447Z","iopub.execute_input":"2023-09-17T06:01:28.472795Z","iopub.status.idle":"2023-09-17T06:01:31.894822Z","shell.execute_reply.started":"2023-09-17T06:01:28.472706Z","shell.execute_reply":"2023-09-17T06:01:31.893961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3- Data Preparation**","metadata":{"_uuid":"ab232952-1cbe-44c5-9cf8-f0fd33f6d446","_cell_guid":"da4f4c90-5cc2-4352-b8cd-acf3f5b6c8f5","trusted":true}},{"cell_type":"code","source":"# Create a meta file for nii files processing\n\nfile_list = []\nfor dirname, _, filenames in os.walk('../input/liver-tumor-segmentation'):\n    for filename in filenames:\n        file_list.append((dirname, filename)) \n\nfor dirname, _, filenames in os.walk('../input/liver-tumor-segmentation-part-2'):\n    for filename in filenames:\n        file_list.append((dirname, filename)) \n\ndf_files = pd.DataFrame(file_list, columns =['dirname', 'filename']) \ndf_files.sort_values(by=['filename'], ascending=True)","metadata":{"_uuid":"8606b1d4-09f8-48eb-a6c7-828375856099","_cell_guid":"c410ed90-a924-470a-9aad-274fcbff2583","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:31.896645Z","iopub.execute_input":"2023-09-17T06:01:31.896924Z","iopub.status.idle":"2023-09-17T06:01:32.070764Z","shell.execute_reply.started":"2023-09-17T06:01:31.896887Z","shell.execute_reply":"2023-09-17T06:01:32.069893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map CT scan and label \n\ndf_files[\"mask_dirname\"]  = \"\"\ndf_files[\"mask_filename\"] = \"\"\n\nfor i in range(131):\n    ct = f\"volume-{i}.nii\"\n    mask = f\"segmentation-{i}.nii\"\n    \n    df_files.loc[df_files['filename'] == ct, 'mask_filename'] = mask\n    df_files.loc[df_files['filename'] == ct, 'mask_dirname'] = \"../input/liver-tumor-segmentation/segmentations\"\n\n# drop segment rows\ndf_files = df_files[df_files.mask_filename != ''].sort_values(by=['filename']).reset_index(drop=True) \n\ndf_files","metadata":{"_uuid":"5fda5cd9-2fb6-4514-bb59-bc668ab30449","_cell_guid":"06c308e2-f696-45c1-863c-432eb284a106","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:32.072399Z","iopub.execute_input":"2023-09-17T06:01:32.072705Z","iopub.status.idle":"2023-09-17T06:01:32.262964Z","shell.execute_reply.started":"2023-09-17T06:01:32.072666Z","shell.execute_reply":"2023-09-17T06:01:32.262190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_nii(filepath):\n    '''\n    Reads .nii file and returns pixel array\n    '''\n    ct_scan = nib.load(filepath)\n    array   = ct_scan.get_fdata()\n    array   = np.rot90(np.array(array))\n    return(array)","metadata":{"_uuid":"b1778542-a2c7-43bf-b62a-2565c19d21b4","_cell_guid":"f6c62bf3-912b-4b6a-80ea-62977f633832","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:32.269175Z","iopub.execute_input":"2023-09-17T06:01:32.269603Z","iopub.status.idle":"2023-09-17T06:01:32.276770Z","shell.execute_reply.started":"2023-09-17T06:01:32.269553Z","shell.execute_reply":"2023-09-17T06:01:32.275190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read sample\n\nsample = 0\nsample_ct = read_nii(df_files.loc[sample,'dirname']+\"/\"+df_files.loc[sample,'filename'])\nsample_mask = read_nii(df_files.loc[sample,'mask_dirname']+\"/\"+df_files.loc[sample,'mask_filename'])\n\nprint(f'CT Shape:   {sample_ct.shape}\\nMask Shape: {sample_mask.shape}')","metadata":{"_uuid":"dc593515-da28-435a-a8de-d967b7543424","_cell_guid":"dea7ebea-ecfb-4246-a573-24aeb483319d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:32.278367Z","iopub.execute_input":"2023-09-17T06:01:32.278692Z","iopub.status.idle":"2023-09-17T06:01:33.357544Z","shell.execute_reply.started":"2023-09-17T06:01:32.278653Z","shell.execute_reply":"2023-09-17T06:01:33.356749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.amin(sample_ct), np.amax(sample_ct))\nprint(np.amin(sample_mask), np.amax(sample_mask))","metadata":{"_uuid":"db79a33f-9380-4ecf-952f-d21558743e90","_cell_guid":"a28dcc6e-42c9-49ba-96a3-8222a42c77cc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:33.358811Z","iopub.execute_input":"2023-09-17T06:01:33.359597Z","iopub.status.idle":"2023-09-17T06:01:33.452182Z","shell.execute_reply.started":"2023-09-17T06:01:33.359557Z","shell.execute_reply":"2023-09-17T06:01:33.451290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dicom_windows = types.SimpleNamespace(\n    brain=(80,40),\n    subdural=(254,100),\n    stroke=(8,32),\n    brain_bone=(2800,600),\n    brain_soft=(375,40),\n    lungs=(1500,-600),\n    mediastinum=(350,50),\n    abdomen_soft=(400,50),\n    liver=(150,30),\n    spine_soft=(250,50),\n    spine_bone=(1800,400),\n    custom = (200,60)\n)\n\n@patch\ndef windowed(self:Tensor, w, l):\n    px = self.clone()\n    px_min = l - w//2\n    px_max = l + w//2\n    px[px<px_min] = px_min\n    px[px>px_max] = px_max\n    return (px-px_min) / (px_max-px_min)\n\nfigure(figsize=(8, 6), dpi=100)\n\nplt.imshow(tensor(sample_ct[..., 55].astype(np.float32)).windowed(*dicom_windows.liver), cmap=plt.cm.bone);","metadata":{"_uuid":"5aaa1f2b-f870-45ca-9048-145882b13a69","_cell_guid":"4c49258a-80a1-4077-8b18-5a58eed588d1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:33.453628Z","iopub.execute_input":"2023-09-17T06:01:33.453965Z","iopub.status.idle":"2023-09-17T06:01:33.829644Z","shell.execute_reply.started":"2023-09-17T06:01:33.453927Z","shell.execute_reply":"2023-09-17T06:01:33.828227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sample(array_list, color_map = 'nipy_spectral'):\n    '''Plots and a slice with all available annotations'''\n    fig = plt.figure(figsize=(20,16), dpi=100)\n\n    plt.subplot(1,4,1)\n    plt.imshow(array_list[0], cmap='bone')\n    plt.title('Original Image')\n    plt.axis('off')\n    \n    plt.subplot(1,4,2)\n    plt.imshow(tensor(array_list[0].astype(np.float32)).windowed(*dicom_windows.liver), cmap='bone');\n    plt.title('Windowed Image')\n    plt.axis('off')\n             \n    plt.subplot(1,4,3)\n    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n    plt.title('Mask')\n    plt.axis('off')\n    \n    plt.subplot(1,4,4)\n    plt.imshow(array_list[0], cmap='bone')\n    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n    plt.title('Liver & Mask')\n    plt.axis('off')\n    \n    plt.show()","metadata":{"_uuid":"7de6c43e-cc13-4807-9968-b3fc15d4a044","_cell_guid":"49eb151d-60b3-46a6-8dfb-ebeee0fcfd80","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:33.830706Z","iopub.execute_input":"2023-09-17T06:01:33.830925Z","iopub.status.idle":"2023-09-17T06:01:33.843051Z","shell.execute_reply.started":"2023-09-17T06:01:33.830895Z","shell.execute_reply":"2023-09-17T06:01:33.842360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = 55\n\nsample_slice = tensor(sample_ct[...,sample].astype(np.float32))\n\nplot_sample([sample_ct[..., sample],\n             sample_mask[..., sample]])","metadata":{"_uuid":"99b2eb7a-80eb-4ecd-bb2b-665cf091ad9b","_cell_guid":"3f633c69-3e06-4f54-b02c-b6ad3d50090a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:33.844646Z","iopub.execute_input":"2023-09-17T06:01:33.845133Z","iopub.status.idle":"2023-09-17T06:01:34.383680Z","shell.execute_reply.started":"2023-09-17T06:01:33.845095Z","shell.execute_reply":"2023-09-17T06:01:34.382268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the mask values\nmask = Image.fromarray(sample_mask[...,sample].astype('uint8'), mode=\"L\")\nunique, counts = np.unique(mask, return_counts=True)\nprint(np.array((unique, counts)).T)","metadata":{"_uuid":"2ec2b037-d747-469e-aa58-a960c405fb98","_cell_guid":"50871a8d-265d-43a8-bbfb-23602f531545","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:34.386595Z","iopub.execute_input":"2023-09-17T06:01:34.387412Z","iopub.status.idle":"2023-09-17T06:01:34.400116Z","shell.execute_reply.started":"2023-09-17T06:01:34.387371Z","shell.execute_reply":"2023-09-17T06:01:34.399183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nclass TensorCTScan(TensorImageBW): _show_args = {'cmap':'bone'}\n\n@patch\ndef freqhist_bins(self:Tensor, n_bins=100):\n    \"A function to split the range of pixel values into groups, such that each group has around the same number of pixels\"\n    imsd = self.view(-1).sort()[0]\n    t = torch.cat([tensor([0.001]),\n                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n                   tensor([0.999])])\n    t = (len(imsd)*t).long()\n    return imsd[t].unique()\n    \n@patch\ndef hist_scaled(self:Tensor, brks=None):\n    \"Scales a tensor using `freqhist_bins` to values between 0 and 1\"\n    if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n    if brks is None: brks = self.freqhist_bins()\n    ys = np.linspace(0., 1., len(brks))\n    x = self.numpy().flatten()\n    x = np.interp(x, brks.numpy(), ys)\n    return tensor(x).reshape(self.shape).clamp(0.,1.)\n    \n    \n@patch\ndef to_nchan(x:Tensor, wins, bins=None):\n    res = [x.windowed(*win) for win in wins]\n    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))\n    dim = [0,1][x.dim()==3]\n    return TensorCTScan(torch.stack(res, dim=dim))\n\n@patch\ndef save_jpg(x:(Tensor), path, wins, bins=None, quality=120):\n    fn = Path(path).with_suffix('.jpg')\n    x = (x.to_nchan(wins, bins)*255).byte()\n    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])\n    im.save(fn, quality=quality)\n\n_,axs = subplots(1,1)\n\nsample_slice.save_jpg('test.jpg', [dicom_windows.liver, dicom_windows.custom])\nshow_image(Image.open('test.jpg'), ax=axs[0], figsize=(8, 6))","metadata":{"_uuid":"9272e8f6-d7cb-4dd2-bb88-74631049b5dd","_cell_guid":"2abb6ca5-cd68-4161-84b8-6bee151b3b71","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:34.401396Z","iopub.execute_input":"2023-09-17T06:01:34.401989Z","iopub.status.idle":"2023-09-17T06:01:34.671870Z","shell.execute_reply.started":"2023-09-17T06:01:34.401951Z","shell.execute_reply":"2023-09-17T06:01:34.670743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nGENERATE_JPG_FILES = True\n\nif (GENERATE_JPG_FILES) :\n    \n    path = Path(\".\")\n\n    os.makedirs('train_images',exist_ok=True)\n    os.makedirs('train_masks',exist_ok=True)\n\n    for ii in tqdm(range(0,len(df_files),3)): # take 1/3 nii files for training\n        curr_ct        = read_nii(df_files.loc[ii,'dirname']+\"/\"+df_files.loc[ii,'filename'])\n        curr_mask      = read_nii(df_files.loc[ii,'mask_dirname']+\"/\"+df_files.loc[ii,'mask_filename'])\n        curr_file_name = str(df_files.loc[ii,'filename']).split('.')[0]\n        curr_dim       = curr_ct.shape[2] # 512, 512, curr_dim\n\n        for curr_slice in range(0,curr_dim,2): # export every 2nd slice for training\n            data = tensor(curr_ct[...,curr_slice].astype(np.float32))\n            mask = tensor(curr_mask[...,curr_slice].astype(np.float32))\n            data.save_jpg(f\"train_images/{curr_file_name}_slice_{curr_slice}.jpg\", [dicom_windows.liver,dicom_windows.custom])\n            mask.save_jpg(f\"train_masks/{curr_file_name}_slice_{curr_slice}_mask.jpg\", [dicom_windows.liver,dicom_windows.custom])\nelse:\n    path = Path(\"../input/liver-segmentation-with-fastai-v2\") # read jpg from saved kernel output","metadata":{"_uuid":"6262086a-fe6d-4bb9-9636-23a1824cc789","_cell_guid":"51d78768-2b1b-42ea-9c67-e440117d1ce8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:01:34.673516Z","iopub.execute_input":"2023-09-17T06:01:34.674280Z","iopub.status.idle":"2023-09-17T06:20:19.379499Z","shell.execute_reply.started":"2023-09-17T06:01:34.674220Z","shell.execute_reply":"2023-09-17T06:20:19.378697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a meta file for nii files processing\nfile_list = []\nmask_list = []\nfor dirname, _, filenames in os.walk('/kaggle/working/train_images'):\n    for filename in filenames:\n        file_list.append(filename) \n\nfor dirname, _, filenames in os.walk('/kaggle/working/train_masks'):\n    for filename in filenames:\n        mask_list.append(filename) \n\nfiles = pd.DataFrame({\"train\": file_list, \"mask\": mask_list})","metadata":{"_uuid":"9a945edb-6676-478d-ae07-a9192161ce2d","_cell_guid":"e73614ba-68c1-4773-ab35-f5e9fdb94768","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:20:19.380842Z","iopub.execute_input":"2023-09-17T06:20:19.381711Z","iopub.status.idle":"2023-09-17T06:20:19.426867Z","shell.execute_reply.started":"2023-09-17T06:20:19.381668Z","shell.execute_reply":"2023-09-17T06:20:19.426132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = []\nfor i in range(len(files)):\n    root = \"/kaggle/working/train_images\"\n    path = os.path.join(root, files[\"train\"][i])\n    filename.append(path)","metadata":{"_uuid":"775d4f56-4ab0-4053-95fb-25dc164a0fc1","_cell_guid":"2a5f7bea-4128-4b75-b357-de8faa5afb3c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:20:19.428361Z","iopub.execute_input":"2023-09-17T06:20:19.428896Z","iopub.status.idle":"2023-09-17T06:20:19.543466Z","shell.execute_reply.started":"2023-09-17T06:20:19.428857Z","shell.execute_reply":"2023-09-17T06:20:19.542649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = []\nfor i in range(len(files)):\n    root = \"/kaggle/working/train_masks\"\n    path = os.path.join(root, files[\"train\"][i])\n    mask.append(path)","metadata":{"_uuid":"f8c54ab0-6ce2-4d52-8fd3-928dbad523f6","_cell_guid":"3022b467-5475-46da-8b1c-2992709ebaf7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:20:19.544957Z","iopub.execute_input":"2023-09-17T06:20:19.545247Z","iopub.status.idle":"2023-09-17T06:20:19.656987Z","shell.execute_reply.started":"2023-09-17T06:20:19.545197Z","shell.execute_reply":"2023-09-17T06:20:19.656251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data={\"filename\": filename, 'mask' : mask})","metadata":{"_uuid":"4d7da4b0-f291-4a91-b3da-2072c2fdaae1","_cell_guid":"8e4e6e95-4483-41d8-a16e-ab72db6abcb2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:20:19.658129Z","iopub.execute_input":"2023-09-17T06:20:19.658409Z","iopub.status.idle":"2023-09-17T06:20:19.666062Z","shell.execute_reply.started":"2023-09-17T06:20:19.658374Z","shell.execute_reply":"2023-09-17T06:20:19.665218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['mask'] = df['mask'].str.split(\".\").str[0] + \"_mask.jpg\"","metadata":{"_uuid":"b052fd7e-85c9-4352-9e06-cba9c3b2c792","_cell_guid":"c1536f92-c29c-49db-8da4-63297759f20a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:20:19.666942Z","iopub.execute_input":"2023-09-17T06:20:19.667165Z","iopub.status.idle":"2023-09-17T06:20:19.698755Z","shell.execute_reply.started":"2023-09-17T06:20:19.667138Z","shell.execute_reply":"2023-09-17T06:20:19.697967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\nimage= cv2.imread(df['mask'][5])\nprint(image.shape)\nplt.imshow(image)\nplt.show()","metadata":{"_uuid":"f37c67bd-2347-4ca5-bbd6-8f4286ce0e3e","_cell_guid":"55387f04-ba38-45fe-acc4-fa14d2f66194","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:20:19.700008Z","iopub.execute_input":"2023-09-17T06:20:19.700285Z","iopub.status.idle":"2023-09-17T06:20:19.960657Z","shell.execute_reply.started":"2023-09-17T06:20:19.700249Z","shell.execute_reply":"2023-09-17T06:20:19.959932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df,test_size = 0.1, random_state = 42)\ndf_train, df_val = train_test_split(df_train,test_size = 0.2, random_state = 42)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","metadata":{"_uuid":"8a49b046-975a-4332-adcd-8c7ba044edde","_cell_guid":"49f6adf8-dd0c-43bf-8123-d01a27809d0c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:20:19.961944Z","iopub.execute_input":"2023-09-17T06:20:19.962618Z","iopub.status.idle":"2023-09-17T06:20:19.976939Z","shell.execute_reply.started":"2023-09-17T06:20:19.962586Z","shell.execute_reply":"2023-09-17T06:20:19.975987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy as np \nimport os\nimport glob\nimport skimage.io as io\nimport skimage.transform as trans\nimport sys\n# from mode.config import *\nnp.set_printoptions(threshold=sys.maxsize, precision=5, suppress=True)\n\ntumor = [120,0,0]\nliver = [0,255,0]\nUnlabelled = [0,0,0]\n\nCOLOR_DICT = np.array([ tumor, liver, Unlabelled])\nclass_name = [ 'tumor', 'liver', 'None']  # You must define by yourself\n\ncolor = 'grayscale'\n\nnum_classes = 3 # include cat, dog and None.\n# num_of_test_img = arg.img_num\n\ntest_img_size = 256 * 256\n\nimg_size = (256,256)\n\n\n\ndef adjustData(img,mask,flag_multi_class,num_class):\n    if(flag_multi_class):\n        img = img / 255.\n        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n        mask[(mask!=0.)&(mask!=255.)&(mask!=128.)] = 0.\n        new_mask = np.zeros(mask.shape + (num_class,))\n        new_mask[mask == 255.,   0] = 1\n        new_mask[mask == 128.,   1] = 1\n        new_mask[mask == 0.,   2] = 1\n        mask = new_mask\n\n    elif(np.max(img) > 1):\n        img = img / 255.\n        mask = mask /255.\n        mask[mask > 0.5] = 1\n        mask[mask <= 0.5] = 0\n    return (img,mask)\n\n\n\ndef trainGenerator( batch_size, dataframe, aug_dict, image_color_mode = \"grayscale\",\n                    mask_color_mode = \"grayscale\", image_save_prefix  = \"image\", mask_save_prefix  = \"mask\",\n                    flag_multi_class = True, num_class = num_classes , save_to_dir = None, target_size = img_size, seed = 1):\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    image_generator = image_datagen.flow_from_dataframe(\n        dataframe,\n        x_col = \"filename\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n    mask_generator = mask_datagen.flow_from_dataframe(\n        dataframe,\n        x_col = \"mask\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n#     print('classes:',image_generator.class_indices, mask_generator.class_indices)\n    train_generator = zip(image_generator, mask_generator)\n    for (img,mask) in train_generator:\n        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n        yield (img,mask)","metadata":{"_uuid":"c32a77b5-1b39-4c75-b6ce-88848e2aee74","_cell_guid":"bf4ce016-6e2f-4f94-a9be-78fea40f0230","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:20:19.978783Z","iopub.execute_input":"2023-09-17T06:20:19.979058Z","iopub.status.idle":"2023-09-17T06:20:25.354741Z","shell.execute_reply.started":"2023-09-17T06:20:19.979028Z","shell.execute_reply":"2023-09-17T06:20:25.353921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\n# from keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras import backend as keras\n# from mode.config import *\n# from tensorflow.contrib.opt import AdamWOptimizer\nfrom tensorflow.python.keras.optimizers import TFOptimizer\nfrom tensorflow.keras import backend as K\nfrom keras.models import Model\n\nimg_size = (256,256,1) # 256 * 256 grayscale img with 1 channel\n\ndr_rate = 0.6 # never mind\nleakyrelu_alpha = 0.3\n\ndef unet(pretrained_weights = None,input_size = img_size):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = LeakyReLU(alpha=leakyrelu_alpha)(conv1)\n    #conv1 = Dropout(dr_rate)(conv1) ###\n    conv1 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    conv1 = BatchNormalization()(conv1)    \n    conv1 = LeakyReLU(alpha=leakyrelu_alpha)(conv1)\n    #conv1 = Dropout(dr_rate)(conv1) ###\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    #pool1 = Dropout(dr_rate)(pool1) ### \n    \n    conv2 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = LeakyReLU(alpha=leakyrelu_alpha)(conv2)\n    #conv2 = Dropout(dr_rate)(conv2)###\n    conv2 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = LeakyReLU(alpha=leakyrelu_alpha)(conv2)    \n    #conv2 = Dropout(dr_rate)(conv2)###    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    \n    conv3 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = LeakyReLU(alpha=leakyrelu_alpha)(conv3)\n    #conv3 = Dropout(dr_rate)(conv3) ###\n    conv3 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = LeakyReLU(alpha=leakyrelu_alpha)(conv3)\n    #conv3 = Dropout(dr_rate)(conv3) ###\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    \n    conv4 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = LeakyReLU(alpha=leakyrelu_alpha)(conv4)    \n    #conv4 = Dropout(dr_rate)(conv4) ###\n    conv4 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = LeakyReLU(alpha=leakyrelu_alpha)(conv4)\n    drop4 = Dropout(dr_rate)(conv4) ###\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)    \n\n    conv5 = Conv2D(1024, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = BatchNormalization()(conv5)    \n    conv5 = LeakyReLU(alpha=leakyrelu_alpha)(conv5)\n    #conv5 = Dropout(dr_rate)(conv5) ###\n    conv5 = Conv2D(1024, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    conv5 = BatchNormalization()(conv5)\n    drop5 = LeakyReLU(alpha=leakyrelu_alpha)(conv5)\n    #drop5 = Dropout(dr_rate)(conv5) ###\n\n    up6 = Conv2D(512, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    up6 = LeakyReLU(alpha=leakyrelu_alpha)(up6)\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = LeakyReLU(alpha=leakyrelu_alpha)(conv6)\n    #conv6 = Dropout(dr_rate)(conv6) ###\n    conv6 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = LeakyReLU(alpha=leakyrelu_alpha)(conv6)    \n    #conv6 = Dropout(dr_rate)(conv6) ###   \n\n    up7 = Conv2D(256, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    up7 = BatchNormalization()(up7)    \n    up7 = LeakyReLU(alpha=leakyrelu_alpha)(up7)\n    up7 = Dropout(dr_rate)(up7) ###\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = BatchNormalization()(conv7)    \n    conv7 = LeakyReLU(alpha=leakyrelu_alpha)(conv7)    \n    #conv7 = Dropout(dr_rate)(conv7) ###\n    conv7 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv7)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = LeakyReLU(alpha=leakyrelu_alpha)(conv7)\n    #conv7 = Dropout(dr_rate)(conv7) ###   \n\n    up8 = Conv2D(128, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    up8 = BatchNormalization()(up8)\n    up8 = LeakyReLU(alpha=0.3)(up8)\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = BatchNormalization()(conv8)\n    conv8 = LeakyReLU(alpha=0.3)(conv8)\n    #conv8 = Dropout(dr_rate)(conv8) ###\n    conv8 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv8)\n    conv8 = BatchNormalization()(conv8)    \n    conv8 = LeakyReLU(alpha=0.3)(conv8)    \n    #conv8 = Dropout(dr_rate)(conv8) ###    \n\n    up9 = Conv2D(64, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    up9 = BatchNormalization()(up9)\n    up9 = LeakyReLU(alpha=leakyrelu_alpha)(up9)\n    up9 = Dropout(dr_rate)(up9) ###\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = BatchNormalization()(conv9)\n    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n    #conv9 = Dropout(dr_rate)(conv9) ###\n    conv9 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = BatchNormalization()(conv9)    \n    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n    #conv9 = Dropout(dr_rate)(conv9) ###\n    conv9 = Conv2D(2, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = BatchNormalization()(conv9)\n    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n    #conv9 = Dropout(dr_rate)(conv9) ###\n\n    conv10 = Conv2D(3, 1, activation = 'softmax')(conv9)\n    model = Model(inputs = inputs, outputs = conv10)   \n    model.compile(optimizer = Adam(lr = 3e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    \n    #model.summary()\n\n    if(pretrained_weights):\n    \tmodel.load_weights(pretrained_weights)\n\n    return model","metadata":{"_uuid":"0477a3c4-68a6-4e3e-9004-d17135e45dde","_cell_guid":"b9dace59-f728-4b30-9530-a9f9cda55b0a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T06:20:25.356216Z","iopub.execute_input":"2023-09-17T06:20:25.356566Z","iopub.status.idle":"2023-09-17T06:20:25.680091Z","shell.execute_reply.started":"2023-09-17T06:20:25.356526Z","shell.execute_reply":"2023-09-17T06:20:25.679301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport os.path\n# from model import *\n# from data import *\nfrom keras.models import load_model\nfrom keras.callbacks import History\nimport tensorflow as tf\nimport matplotlib.pyplot as plt \nfrom keras import backend as K\n# from mode.config import *\n# from csvrecord import * \nfrom pathlib import Path\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\nfrom keras.layers import LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\n\n#from sklearn.model_selection import train_test_split\n\n#df_train, df_val = train_test_split(df, test_size=0.2, random_state=42)\n\ndata_gen_args = dict()\n\nmyGene = trainGenerator(12, df_train, data_gen_args, save_to_dir = None)\nvalGene = trainGenerator(12, df_val, data_gen_args, save_to_dir=None)\n\nmodel = unet()\n# model_checkpoint = ModelCheckpoint(model_name, monitor='loss',verbose=1, save_best_only=True)\n#history = model.fit_generator(myGene, steps_per_epoch=len(df_val)/32, epochs=50)\nhistory = model.fit_generator(myGene, steps_per_epoch=len(df_val)/32, epochs=5, validation_data=valGene, validation_steps=len(df_val)/32)","metadata":{"_uuid":"b3720f5d-8069-47c2-a020-4e96c75fcce4","_cell_guid":"534efb85-afcc-4376-82f5-194d76521889","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-17T07:07:51.704772Z","iopub.execute_input":"2023-09-17T07:07:51.705129Z","iopub.status.idle":"2023-09-17T07:07:57.648997Z","shell.execute_reply.started":"2023-09-17T07:07:51.705028Z","shell.execute_reply":"2023-09-17T07:07:57.647972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"76d9f5f9-1943-40a7-be99-bcdb9551f8ee","_cell_guid":"ed6ea501-18c9-4c36-bcca-bcf2a7e46f29","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}