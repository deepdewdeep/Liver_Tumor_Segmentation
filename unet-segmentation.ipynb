{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:08:33.483748Z","iopub.status.busy":"2023-08-27T12:08:33.483282Z","iopub.status.idle":"2023-08-27T12:08:37.159571Z","shell.execute_reply":"2023-08-27T12:08:37.158808Z","shell.execute_reply.started":"2023-08-27T12:08:33.483658Z"},"trusted":true},"outputs":[],"source":["import os\n","import glob\n","import cv2\n","import imageio\n","\n","import numpy as np \n","import pandas as pd \n","import nibabel as nib\n","import matplotlib.pyplot as plt\n","\n","from tqdm.notebook import tqdm\n","from ipywidgets import *\n","from PIL import Image\n","from matplotlib.pyplot import figure\n","\n","from fastai.basics import *\n","from fastai.vision.all import *\n","from fastai.data.transforms import *"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" 10.13\n"]}],"source":["print (\"%6.2f\"%(10.1280))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:08:39.940978Z","iopub.status.busy":"2023-08-27T12:08:39.940218Z","iopub.status.idle":"2023-08-27T12:08:40.123555Z","shell.execute_reply":"2023-08-27T12:08:40.122696Z","shell.execute_reply.started":"2023-08-27T12:08:39.940925Z"},"trusted":true},"outputs":[],"source":["# Create a meta file for nii files processing\n","\n","file_list = []\n","for dirname, _, filenames in os.walk('../input/liver-tumor-segmentation'):\n","    for filename in filenames:\n","        file_list.append((dirname, filename)) \n","\n","for dirname, _, filenames in os.walk('../input/liver-tumor-segmentation-part-2'):\n","    for filename in filenames:\n","        file_list.append((dirname, filename)) \n","\n","df_files = pd.DataFrame(file_list, columns =['dirname', 'filename']) \n","df_files.sort_values(by=['filename'], ascending=True)    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:08:41.600695Z","iopub.status.busy":"2023-08-27T12:08:41.600412Z","iopub.status.idle":"2023-08-27T12:08:41.792273Z","shell.execute_reply":"2023-08-27T12:08:41.791568Z","shell.execute_reply.started":"2023-08-27T12:08:41.600662Z"},"trusted":true},"outputs":[],"source":["# Map CT scan and label \n","\n","df_files[\"mask_dirname\"]  = \"\"\n","df_files[\"mask_filename\"] = \"\"\n","\n","for i in range(131):\n","    ct = f\"volume-{i}.nii\"\n","    mask = f\"segmentation-{i}.nii\"\n","    \n","    df_files.loc[df_files['filename'] == ct, 'mask_filename'] = mask\n","    df_files.loc[df_files['filename'] == ct, 'mask_dirname'] = \"../input/liver-tumor-segmentation/segmentations\"\n","\n","# drop segment rows\n","df_files = df_files[df_files.mask_filename != ''].sort_values(by=['filename']).reset_index(drop=True) \n","\n","df_files"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:08:41.991878Z","iopub.status.busy":"2023-08-27T12:08:41.991609Z","iopub.status.idle":"2023-08-27T12:08:41.996825Z","shell.execute_reply":"2023-08-27T12:08:41.995965Z","shell.execute_reply.started":"2023-08-27T12:08:41.991849Z"},"trusted":true},"outputs":[],"source":["def read_nii(filepath):\n","    '''\n","    Reads .nii file and returns pixel array\n","    '''\n","    ct_scan = nib.load(filepath)\n","    array   = ct_scan.get_fdata()\n","    array   = np.rot90(np.array(array))\n","    return(array)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:08:48.422396Z","iopub.status.busy":"2023-08-27T12:08:48.42182Z","iopub.status.idle":"2023-08-27T12:08:49.473999Z","shell.execute_reply":"2023-08-27T12:08:49.472125Z","shell.execute_reply.started":"2023-08-27T12:08:48.422357Z"},"trusted":true},"outputs":[],"source":["# Read sample\n","\n","sample = 0\n","sample_ct = read_nii(df_files.loc[sample,'dirname']+\"/\"+df_files.loc[sample,'filename'])\n","sample_mask = read_nii(df_files.loc[sample,'mask_dirname']+\"/\"+df_files.loc[sample,'mask_filename'])\n","\n","print(f'CT Shape:   {sample_ct.shape}\\nMask Shape: {sample_mask.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:08:49.513945Z","iopub.status.busy":"2023-08-27T12:08:49.513583Z","iopub.status.idle":"2023-08-27T12:08:49.604559Z","shell.execute_reply":"2023-08-27T12:08:49.60383Z","shell.execute_reply.started":"2023-08-27T12:08:49.513912Z"},"trusted":true},"outputs":[],"source":["print(np.amin(sample_ct), np.amax(sample_ct))\n","print(np.amin(sample_mask), np.amax(sample_mask))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:08:56.07644Z","iopub.status.busy":"2023-08-27T12:08:56.075626Z","iopub.status.idle":"2023-08-27T12:08:56.462255Z","shell.execute_reply":"2023-08-27T12:08:56.460221Z","shell.execute_reply.started":"2023-08-27T12:08:56.076389Z"},"trusted":true},"outputs":[],"source":["dicom_windows = types.SimpleNamespace(\n","    brain=(80,40),\n","    subdural=(254,100),\n","    stroke=(8,32),\n","    brain_bone=(2800,600),\n","    brain_soft=(375,40),\n","    lungs=(1500,-600),\n","    mediastinum=(350,50),\n","    abdomen_soft=(400,50),\n","    liver=(150,30),\n","    spine_soft=(250,50),\n","    spine_bone=(1800,400),\n","    custom = (200,60)\n",")\n","\n","@patch\n","def windowed(self:Tensor, w, l):\n","    px = self.clone()\n","    px_min = l - w//2\n","    px_max = l + w//2\n","    px[px<px_min] = px_min\n","    px[px>px_max] = px_max\n","    return (px-px_min) / (px_max-px_min)\n","\n","figure(figsize=(8, 6), dpi=100)\n","\n","plt.imshow(tensor(sample_ct[..., 55].astype(np.float32)).windowed(*dicom_windows.liver), cmap=plt.cm.bone);"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:09:05.224075Z","iopub.status.busy":"2023-08-27T12:09:05.223586Z","iopub.status.idle":"2023-08-27T12:09:05.246224Z","shell.execute_reply":"2023-08-27T12:09:05.245029Z","shell.execute_reply.started":"2023-08-27T12:09:05.224021Z"},"trusted":true},"outputs":[],"source":["def plot_sample(array_list, color_map = 'nipy_spectral'):\n","    '''Plots and a slice with all available annotations'''\n","    fig = plt.figure(figsize=(20,16), dpi=100)\n","\n","    plt.subplot(1,4,1)\n","    plt.imshow(array_list[0], cmap='bone')\n","    plt.title('Original Image')\n","    plt.axis('off')\n","    \n","    plt.subplot(1,4,2)\n","    plt.imshow(tensor(array_list[0].astype(np.float32)).windowed(*dicom_windows.liver), cmap='bone');\n","    plt.title('Windowed Image')\n","    plt.axis('off')\n","             \n","    plt.subplot(1,4,3)\n","    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n","    plt.title('Mask')\n","    plt.axis('off')\n","    \n","    plt.subplot(1,4,4)\n","    plt.imshow(array_list[0], cmap='bone')\n","    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n","    plt.title('Liver & Mask')\n","    plt.axis('off')\n","    \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:09:10.919676Z","iopub.status.busy":"2023-08-27T12:09:10.919394Z","iopub.status.idle":"2023-08-27T12:09:11.457303Z","shell.execute_reply":"2023-08-27T12:09:11.456611Z","shell.execute_reply.started":"2023-08-27T12:09:10.919644Z"},"trusted":true},"outputs":[],"source":["sample = 55\n","\n","sample_slice = tensor(sample_ct[...,sample].astype(np.float32))\n","\n","plot_sample([sample_ct[..., sample],\n","             sample_mask[..., sample]])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:09:14.385493Z","iopub.status.busy":"2023-08-27T12:09:14.384618Z","iopub.status.idle":"2023-08-27T12:09:14.396275Z","shell.execute_reply":"2023-08-27T12:09:14.395369Z","shell.execute_reply.started":"2023-08-27T12:09:14.38544Z"},"trusted":true},"outputs":[],"source":["# Check the mask values\n","mask = Image.fromarray(sample_mask[...,sample].astype('uint8'), mode=\"L\")\n","unique, counts = np.unique(mask, return_counts=True)\n","print(np.array((unique, counts)).T)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:09:20.178217Z","iopub.status.busy":"2023-08-27T12:09:20.177431Z","iopub.status.idle":"2023-08-27T12:09:20.451537Z","shell.execute_reply":"2023-08-27T12:09:20.45057Z","shell.execute_reply.started":"2023-08-27T12:09:20.178168Z"},"trusted":true},"outputs":[],"source":["\n","\n","class TensorCTScan(TensorImageBW): _show_args = {'cmap':'bone'}\n","\n","@patch\n","def freqhist_bins(self:Tensor, n_bins=100):\n","    \"A function to split the range of pixel values into groups, such that each group has around the same number of pixels\"\n","    imsd = self.view(-1).sort()[0]\n","    t = torch.cat([tensor([0.001]),\n","                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n","                   tensor([0.999])])\n","    t = (len(imsd)*t).long()\n","    return imsd[t].unique()\n","    \n","@patch\n","def hist_scaled(self:Tensor, brks=None):\n","    \"Scales a tensor using `freqhist_bins` to values between 0 and 1\"\n","    if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n","    if brks is None: brks = self.freqhist_bins()\n","    ys = np.linspace(0., 1., len(brks))\n","    x = self.numpy().flatten()\n","    x = np.interp(x, brks.numpy(), ys)\n","    return tensor(x).reshape(self.shape).clamp(0.,1.)\n","    \n","    \n","@patch\n","def to_nchan(x:Tensor, wins, bins=None):\n","    res = [x.windowed(*win) for win in wins]\n","    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))\n","    dim = [0,1][x.dim()==3]\n","    return TensorCTScan(torch.stack(res, dim=dim))\n","\n","@patch\n","def save_jpg(x:(Tensor), path, wins, bins=None, quality=120):\n","    fn = Path(path).with_suffix('.jpg')\n","    x = (x.to_nchan(wins, bins)*255).byte()\n","    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])\n","    im.save(fn, quality=quality)\n","\n","_,axs = subplots(1,1)\n","\n","sample_slice.save_jpg('test.jpg', [dicom_windows.liver, dicom_windows.custom])\n","show_image(Image.open('test.jpg'), ax=axs[0], figsize=(8, 6))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-27T12:09:26.070169Z","iopub.status.busy":"2023-08-27T12:09:26.069883Z"},"trusted":true},"outputs":[],"source":["\n","GENERATE_JPG_FILES = True\n","\n","if (GENERATE_JPG_FILES) :\n","    \n","    path = Path(\".\")\n","\n","    os.makedirs('train_images',exist_ok=True)\n","    os.makedirs('train_masks',exist_ok=True)\n","\n","    for ii in tqdm(range(0,len(df_files),3)): # take 1/3 nii files for training\n","        curr_ct        = read_nii(df_files.loc[ii,'dirname']+\"/\"+df_files.loc[ii,'filename'])\n","        curr_mask      = read_nii(df_files.loc[ii,'mask_dirname']+\"/\"+df_files.loc[ii,'mask_filename'])\n","        curr_file_name = str(df_files.loc[ii,'filename']).split('.')[0]\n","        curr_dim       = curr_ct.shape[2] # 512, 512, curr_dim\n","\n","        for curr_slice in range(0,curr_dim,2): # export every 2nd slice for training\n","            data = tensor(curr_ct[...,curr_slice].astype(np.float32))\n","            mask = tensor(curr_mask[...,curr_slice].astype(np.float32))\n","            data.save_jpg(f\"train_images/{curr_file_name}_slice_{curr_slice}.jpg\", [dicom_windows.liver,dicom_windows.custom])\n","            mask.save_jpg(f\"train_masks/{curr_file_name}_slice_{curr_slice}_mask.jpg\", [dicom_windows.liver,dicom_windows.custom])\n","else:\n","    path = Path(\"../input/liver-segmentation-with-fastai-v2\") # read jpg from saved kernel output"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create a meta file for nii files processing\n","file_list = []\n","mask_list = []\n","for dirname, _, filenames in os.walk('/kaggle/working/train_images'):\n","    for filename in filenames:\n","        file_list.append(filename) \n","\n","for dirname, _, filenames in os.walk('/kaggle/working/train_masks'):\n","    for filename in filenames:\n","        mask_list.append(filename) \n","\n","files = pd.DataFrame({\"train\": file_list, \"mask\": mask_list}) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T11:31:51.633144Z","iopub.status.busy":"2023-03-06T11:31:51.632877Z","iopub.status.idle":"2023-03-06T11:31:51.71317Z","shell.execute_reply":"2023-03-06T11:31:51.712417Z","shell.execute_reply.started":"2023-03-06T11:31:51.63311Z"},"trusted":true},"outputs":[],"source":["filename = []\n","for i in range(len(files)):\n","    root = \"/kaggle/working/train_images\"\n","    path = os.path.join(root, files[\"train\"][i])\n","    filename.append(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T11:31:51.714602Z","iopub.status.busy":"2023-03-06T11:31:51.714283Z","iopub.status.idle":"2023-03-06T11:31:51.792648Z","shell.execute_reply":"2023-03-06T11:31:51.792Z","shell.execute_reply.started":"2023-03-06T11:31:51.714567Z"},"trusted":true},"outputs":[],"source":["mask = []\n","for i in range(len(files)):\n","    root = \"/kaggle/working/train_masks\"\n","    path = os.path.join(root, files[\"train\"][i])\n","    mask.append(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T11:31:51.794175Z","iopub.status.busy":"2023-03-06T11:31:51.793924Z","iopub.status.idle":"2023-03-06T11:31:51.799674Z","shell.execute_reply":"2023-03-06T11:31:51.798736Z","shell.execute_reply.started":"2023-03-06T11:31:51.794142Z"},"trusted":true},"outputs":[],"source":["df = pd.DataFrame(data={\"filename\": filename, 'mask' : mask})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T11:31:51.80143Z","iopub.status.busy":"2023-03-06T11:31:51.801174Z","iopub.status.idle":"2023-03-06T11:31:51.830566Z","shell.execute_reply":"2023-03-06T11:31:51.829886Z","shell.execute_reply.started":"2023-03-06T11:31:51.801397Z"},"trusted":true},"outputs":[],"source":["df['mask'] = df['mask'].str.split(\".\").str[0] + \"_mask.jpg\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T11:33:36.500437Z","iopub.status.busy":"2023-03-06T11:33:36.500038Z","iopub.status.idle":"2023-03-06T11:33:36.707569Z","shell.execute_reply":"2023-03-06T11:33:36.706837Z","shell.execute_reply.started":"2023-03-06T11:33:36.500406Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","\n","image= cv2.imread(df['mask'][5])\n","print(image.shape)\n","plt.imshow(image)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T11:31:52.072297Z","iopub.status.busy":"2023-03-06T11:31:52.072034Z","iopub.status.idle":"2023-03-06T11:31:52.087204Z","shell.execute_reply":"2023-03-06T11:31:52.086697Z","shell.execute_reply.started":"2023-03-06T11:31:52.072262Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","df_train, df_test = train_test_split(df,test_size = 0.1, random_state = 42)\n","df_train, df_val = train_test_split(df_train,test_size = 0.2, random_state = 42)\n","print(df_train.values.shape)\n","print(df_val.values.shape)\n","print(df_test.values.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T11:31:52.088908Z","iopub.status.busy":"2023-03-06T11:31:52.088493Z","iopub.status.idle":"2023-03-06T11:31:57.954603Z","shell.execute_reply":"2023-03-06T11:31:57.953841Z","shell.execute_reply.started":"2023-03-06T11:31:52.088872Z"},"trusted":true},"outputs":[],"source":["from __future__ import print_function\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np \n","import os\n","import glob\n","import skimage.io as io\n","import skimage.transform as trans\n","import sys\n","# from mode.config import *\n","np.set_printoptions(threshold=sys.maxsize, precision=5, suppress=True)\n","\n","tumor = [120,0,0]\n","liver = [0,255,0]\n","Unlabelled = [0,0,0]\n","\n","COLOR_DICT = np.array([ tumor, liver, Unlabelled])\n","class_name = [ 'tumor', 'liver', 'None']  # You must define by yourself\n","\n","color = 'grayscale'\n","\n","num_classes = 3 # include cat, dog and None.\n","# num_of_test_img = arg.img_num\n","\n","test_img_size = 256 * 256\n","\n","img_size = (256,256)\n","\n","\n","\n","def adjustData(img,mask,flag_multi_class,num_class):\n","    if(flag_multi_class):\n","        img = img / 255.\n","        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n","        mask[(mask!=0.)&(mask!=255.)&(mask!=128.)] = 0.\n","        new_mask = np.zeros(mask.shape + (num_class,))\n","        new_mask[mask == 255.,   0] = 1\n","        new_mask[mask == 128.,   1] = 1\n","        new_mask[mask == 0.,   2] = 1\n","        mask = new_mask\n","\n","    elif(np.max(img) > 1):\n","        img = img / 255.\n","        mask = mask /255.\n","        mask[mask > 0.5] = 1\n","        mask[mask <= 0.5] = 0\n","    return (img,mask)\n","\n","\n","\n","def trainGenerator( batch_size, dataframe, aug_dict, image_color_mode = \"grayscale\",\n","                    mask_color_mode = \"grayscale\", image_save_prefix  = \"image\", mask_save_prefix  = \"mask\",\n","                    flag_multi_class = True, num_class = num_classes , save_to_dir = None, target_size = img_size, seed = 1):\n","    image_datagen = ImageDataGenerator(**aug_dict)\n","    mask_datagen = ImageDataGenerator(**aug_dict)\n","    image_generator = image_datagen.flow_from_dataframe(\n","        dataframe,\n","        x_col = \"filename\",\n","        class_mode = None,\n","        color_mode = image_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = image_save_prefix,\n","        seed = seed)\n","    mask_generator = mask_datagen.flow_from_dataframe(\n","        dataframe,\n","        x_col = \"mask\",\n","        class_mode = None,\n","        color_mode = mask_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = mask_save_prefix,\n","        seed = seed)\n","#     print('classes:',image_generator.class_indices, mask_generator.class_indices)\n","    train_generator = zip(image_generator, mask_generator)\n","    for (img,mask) in train_generator:\n","        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n","        yield (img,mask)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T11:34:46.778589Z","iopub.status.busy":"2023-03-06T11:34:46.778021Z","iopub.status.idle":"2023-03-06T11:34:46.809583Z","shell.execute_reply":"2023-03-06T11:34:46.808855Z","shell.execute_reply.started":"2023-03-06T11:34:46.778541Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import os\n","import skimage.io as io\n","import skimage.transform as trans\n","import numpy as np\n","# from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras import backend as keras\n","# from mode.config import *\n","# from tensorflow.contrib.opt import AdamWOptimizer\n","from tensorflow.python.keras.optimizers import TFOptimizer\n","from tensorflow.keras import backend as K\n","from keras.models import Model\n","\n","img_size = (256,256,1) # 256 * 256 grayscale img with 1 channel\n","\n","dr_rate = 0.6 # never mind\n","leakyrelu_alpha = 0.3\n","\n","def unet(pretrained_weights = None,input_size = img_size):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = LeakyReLU(alpha=leakyrelu_alpha)(conv1)\n","    #conv1 = Dropout(dr_rate)(conv1) ###\n","    conv1 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    conv1 = BatchNormalization()(conv1)    \n","    conv1 = LeakyReLU(alpha=leakyrelu_alpha)(conv1)\n","    #conv1 = Dropout(dr_rate)(conv1) ###\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    #pool1 = Dropout(dr_rate)(pool1) ### \n","    \n","    conv2 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = LeakyReLU(alpha=leakyrelu_alpha)(conv2)\n","    #conv2 = Dropout(dr_rate)(conv2)###\n","    conv2 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = LeakyReLU(alpha=leakyrelu_alpha)(conv2)    \n","    #conv2 = Dropout(dr_rate)(conv2)###    \n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    \n","    conv3 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = LeakyReLU(alpha=leakyrelu_alpha)(conv3)\n","    #conv3 = Dropout(dr_rate)(conv3) ###\n","    conv3 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = LeakyReLU(alpha=leakyrelu_alpha)(conv3)\n","    #conv3 = Dropout(dr_rate)(conv3) ###\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    \n","    conv4 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = LeakyReLU(alpha=leakyrelu_alpha)(conv4)    \n","    #conv4 = Dropout(dr_rate)(conv4) ###\n","    conv4 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = LeakyReLU(alpha=leakyrelu_alpha)(conv4)\n","    drop4 = Dropout(dr_rate)(conv4) ###\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)    \n","\n","    conv5 = Conv2D(1024, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = BatchNormalization()(conv5)    \n","    conv5 = LeakyReLU(alpha=leakyrelu_alpha)(conv5)\n","    #conv5 = Dropout(dr_rate)(conv5) ###\n","    conv5 = Conv2D(1024, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    drop5 = LeakyReLU(alpha=leakyrelu_alpha)(conv5)\n","    #drop5 = Dropout(dr_rate)(conv5) ###\n","\n","    up6 = Conv2D(512, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    up6 = LeakyReLU(alpha=leakyrelu_alpha)(up6)\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = LeakyReLU(alpha=leakyrelu_alpha)(conv6)\n","    #conv6 = Dropout(dr_rate)(conv6) ###\n","    conv6 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = LeakyReLU(alpha=leakyrelu_alpha)(conv6)    \n","    #conv6 = Dropout(dr_rate)(conv6) ###   \n","\n","    up7 = Conv2D(256, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    up7 = BatchNormalization()(up7)    \n","    up7 = LeakyReLU(alpha=leakyrelu_alpha)(up7)\n","    up7 = Dropout(dr_rate)(up7) ###\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = BatchNormalization()(conv7)    \n","    conv7 = LeakyReLU(alpha=leakyrelu_alpha)(conv7)    \n","    #conv7 = Dropout(dr_rate)(conv7) ###\n","    conv7 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = LeakyReLU(alpha=leakyrelu_alpha)(conv7)\n","    #conv7 = Dropout(dr_rate)(conv7) ###   \n","\n","    up8 = Conv2D(128, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    up8 = BatchNormalization()(up8)\n","    up8 = LeakyReLU(alpha=0.3)(up8)\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = BatchNormalization()(conv8)\n","    conv8 = LeakyReLU(alpha=0.3)(conv8)\n","    #conv8 = Dropout(dr_rate)(conv8) ###\n","    conv8 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","    conv8 = BatchNormalization()(conv8)    \n","    conv8 = LeakyReLU(alpha=0.3)(conv8)    \n","    #conv8 = Dropout(dr_rate)(conv8) ###    \n","\n","    up9 = Conv2D(64, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    up9 = BatchNormalization()(up9)\n","    up9 = LeakyReLU(alpha=leakyrelu_alpha)(up9)\n","    up9 = Dropout(dr_rate)(up9) ###\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n","    #conv9 = Dropout(dr_rate)(conv9) ###\n","    conv9 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = BatchNormalization()(conv9)    \n","    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n","    #conv9 = Dropout(dr_rate)(conv9) ###\n","    conv9 = Conv2D(2, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n","    #conv9 = Dropout(dr_rate)(conv9) ###\n","\n","    conv10 = Conv2D(3, 1, activation = 'softmax')(conv9)\n","    model = Model(inputs = inputs, outputs = conv10)   \n","    model.compile(optimizer = Adam(lr = 3e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","    \n","    #model.summary()\n","\n","    if(pretrained_weights):\n","    \tmodel.load_weights(pretrained_weights)\n","\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T11:44:09.029724Z","iopub.status.busy":"2023-03-06T11:44:09.02897Z","iopub.status.idle":"2023-03-06T11:46:24.907095Z","shell.execute_reply":"2023-03-06T11:46:24.906326Z","shell.execute_reply.started":"2023-03-06T11:44:09.029688Z"},"trusted":true},"outputs":[],"source":["import os\n","import os.path\n","# from model import *\n","# from data import *\n","from keras.models import load_model\n","from keras.callbacks import History\n","import tensorflow as tf\n","import matplotlib.pyplot as plt \n","from keras import backend as K\n","# from mode.config import *\n","# from csvrecord import * \n","from pathlib import Path\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n","from keras.layers import LeakyReLU\n","from tensorflow.keras.optimizers import Adam\n","\n","data_gen_args = dict()\n","\n","myGene = trainGenerator(12, df_val, data_gen_args, save_to_dir = None)\n","\n","\n","model = unet()\n","# model_checkpoint = ModelCheckpoint(model_name, monitor='loss',verbose=1, save_best_only=True)\n","history = model.fit_generator(myGene, steps_per_epoch=len(df_val)/32, epochs=5)"]}],"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
