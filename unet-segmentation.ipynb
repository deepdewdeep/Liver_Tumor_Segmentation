{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport cv2\nimport imageio\n\nimport numpy as np \nimport pandas as pd \nimport nibabel as nib\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\nfrom ipywidgets import *\nfrom PIL import Image\nfrom matplotlib.pyplot import figure\n\nfrom fastai.basics import *\nfrom fastai.vision.all import *\nfrom fastai.data.transforms import *","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:08:33.483282Z","iopub.execute_input":"2023-08-27T12:08:33.483748Z","iopub.status.idle":"2023-08-27T12:08:37.159571Z","shell.execute_reply.started":"2023-08-27T12:08:33.483658Z","shell.execute_reply":"2023-08-27T12:08:37.158808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3- Data Preparation**","metadata":{}},{"cell_type":"code","source":"# Create a meta file for nii files processing\n\nfile_list = []\nfor dirname, _, filenames in os.walk('../input/liver-tumor-segmentation'):\n    for filename in filenames:\n        file_list.append((dirname, filename)) \n\nfor dirname, _, filenames in os.walk('../input/liver-tumor-segmentation-part-2'):\n    for filename in filenames:\n        file_list.append((dirname, filename)) \n\ndf_files = pd.DataFrame(file_list, columns =['dirname', 'filename']) \ndf_files.sort_values(by=['filename'], ascending=True)    ","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:08:39.940218Z","iopub.execute_input":"2023-08-27T12:08:39.940978Z","iopub.status.idle":"2023-08-27T12:08:40.123555Z","shell.execute_reply.started":"2023-08-27T12:08:39.940925Z","shell.execute_reply":"2023-08-27T12:08:40.122696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map CT scan and label \n\ndf_files[\"mask_dirname\"]  = \"\"\ndf_files[\"mask_filename\"] = \"\"\n\nfor i in range(131):\n    ct = f\"volume-{i}.nii\"\n    mask = f\"segmentation-{i}.nii\"\n    \n    df_files.loc[df_files['filename'] == ct, 'mask_filename'] = mask\n    df_files.loc[df_files['filename'] == ct, 'mask_dirname'] = \"../input/liver-tumor-segmentation/segmentations\"\n\n# drop segment rows\ndf_files = df_files[df_files.mask_filename != ''].sort_values(by=['filename']).reset_index(drop=True) \n\ndf_files","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:08:41.600412Z","iopub.execute_input":"2023-08-27T12:08:41.600695Z","iopub.status.idle":"2023-08-27T12:08:41.792273Z","shell.execute_reply.started":"2023-08-27T12:08:41.600662Z","shell.execute_reply":"2023-08-27T12:08:41.791568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_nii(filepath):\n    '''\n    Reads .nii file and returns pixel array\n    '''\n    ct_scan = nib.load(filepath)\n    array   = ct_scan.get_fdata()\n    array   = np.rot90(np.array(array))\n    return(array)","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:08:41.991609Z","iopub.execute_input":"2023-08-27T12:08:41.991878Z","iopub.status.idle":"2023-08-27T12:08:41.996825Z","shell.execute_reply.started":"2023-08-27T12:08:41.991849Z","shell.execute_reply":"2023-08-27T12:08:41.995965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read sample\n\nsample = 0\nsample_ct = read_nii(df_files.loc[sample,'dirname']+\"/\"+df_files.loc[sample,'filename'])\nsample_mask = read_nii(df_files.loc[sample,'mask_dirname']+\"/\"+df_files.loc[sample,'mask_filename'])\n\nprint(f'CT Shape:   {sample_ct.shape}\\nMask Shape: {sample_mask.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:08:48.42182Z","iopub.execute_input":"2023-08-27T12:08:48.422396Z","iopub.status.idle":"2023-08-27T12:08:49.473999Z","shell.execute_reply.started":"2023-08-27T12:08:48.422357Z","shell.execute_reply":"2023-08-27T12:08:49.472125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.amin(sample_ct), np.amax(sample_ct))\nprint(np.amin(sample_mask), np.amax(sample_mask))","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:08:49.513583Z","iopub.execute_input":"2023-08-27T12:08:49.513945Z","iopub.status.idle":"2023-08-27T12:08:49.604559Z","shell.execute_reply.started":"2023-08-27T12:08:49.513912Z","shell.execute_reply":"2023-08-27T12:08:49.60383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dicom_windows = types.SimpleNamespace(\n    brain=(80,40),\n    subdural=(254,100),\n    stroke=(8,32),\n    brain_bone=(2800,600),\n    brain_soft=(375,40),\n    lungs=(1500,-600),\n    mediastinum=(350,50),\n    abdomen_soft=(400,50),\n    liver=(150,30),\n    spine_soft=(250,50),\n    spine_bone=(1800,400),\n    custom = (200,60)\n)\n\n@patch\ndef windowed(self:Tensor, w, l):\n    px = self.clone()\n    px_min = l - w//2\n    px_max = l + w//2\n    px[px<px_min] = px_min\n    px[px>px_max] = px_max\n    return (px-px_min) / (px_max-px_min)\n\nfigure(figsize=(8, 6), dpi=100)\n\nplt.imshow(tensor(sample_ct[..., 55].astype(np.float32)).windowed(*dicom_windows.liver), cmap=plt.cm.bone);","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:08:56.075626Z","iopub.execute_input":"2023-08-27T12:08:56.07644Z","iopub.status.idle":"2023-08-27T12:08:56.462255Z","shell.execute_reply.started":"2023-08-27T12:08:56.076389Z","shell.execute_reply":"2023-08-27T12:08:56.460221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sample(array_list, color_map = 'nipy_spectral'):\n    '''Plots and a slice with all available annotations'''\n    fig = plt.figure(figsize=(20,16), dpi=100)\n\n    plt.subplot(1,4,1)\n    plt.imshow(array_list[0], cmap='bone')\n    plt.title('Original Image')\n    plt.axis('off')\n    \n    plt.subplot(1,4,2)\n    plt.imshow(tensor(array_list[0].astype(np.float32)).windowed(*dicom_windows.liver), cmap='bone');\n    plt.title('Windowed Image')\n    plt.axis('off')\n             \n    plt.subplot(1,4,3)\n    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n    plt.title('Mask')\n    plt.axis('off')\n    \n    plt.subplot(1,4,4)\n    plt.imshow(array_list[0], cmap='bone')\n    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n    plt.title('Liver & Mask')\n    plt.axis('off')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:09:05.223586Z","iopub.execute_input":"2023-08-27T12:09:05.224075Z","iopub.status.idle":"2023-08-27T12:09:05.246224Z","shell.execute_reply.started":"2023-08-27T12:09:05.224021Z","shell.execute_reply":"2023-08-27T12:09:05.245029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = 55\n\nsample_slice = tensor(sample_ct[...,sample].astype(np.float32))\n\nplot_sample([sample_ct[..., sample],\n             sample_mask[..., sample]])","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:09:10.919394Z","iopub.execute_input":"2023-08-27T12:09:10.919676Z","iopub.status.idle":"2023-08-27T12:09:11.457303Z","shell.execute_reply.started":"2023-08-27T12:09:10.919644Z","shell.execute_reply":"2023-08-27T12:09:11.456611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the mask values\nmask = Image.fromarray(sample_mask[...,sample].astype('uint8'), mode=\"L\")\nunique, counts = np.unique(mask, return_counts=True)\nprint(np.array((unique, counts)).T)","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:09:14.384618Z","iopub.execute_input":"2023-08-27T12:09:14.385493Z","iopub.status.idle":"2023-08-27T12:09:14.396275Z","shell.execute_reply.started":"2023-08-27T12:09:14.38544Z","shell.execute_reply":"2023-08-27T12:09:14.395369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nclass TensorCTScan(TensorImageBW): _show_args = {'cmap':'bone'}\n\n@patch\ndef freqhist_bins(self:Tensor, n_bins=100):\n    \"A function to split the range of pixel values into groups, such that each group has around the same number of pixels\"\n    imsd = self.view(-1).sort()[0]\n    t = torch.cat([tensor([0.001]),\n                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n                   tensor([0.999])])\n    t = (len(imsd)*t).long()\n    return imsd[t].unique()\n    \n@patch\ndef hist_scaled(self:Tensor, brks=None):\n    \"Scales a tensor using `freqhist_bins` to values between 0 and 1\"\n    if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n    if brks is None: brks = self.freqhist_bins()\n    ys = np.linspace(0., 1., len(brks))\n    x = self.numpy().flatten()\n    x = np.interp(x, brks.numpy(), ys)\n    return tensor(x).reshape(self.shape).clamp(0.,1.)\n    \n    \n@patch\ndef to_nchan(x:Tensor, wins, bins=None):\n    res = [x.windowed(*win) for win in wins]\n    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))\n    dim = [0,1][x.dim()==3]\n    return TensorCTScan(torch.stack(res, dim=dim))\n\n@patch\ndef save_jpg(x:(Tensor), path, wins, bins=None, quality=120):\n    fn = Path(path).with_suffix('.jpg')\n    x = (x.to_nchan(wins, bins)*255).byte()\n    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])\n    im.save(fn, quality=quality)\n\n_,axs = subplots(1,1)\n\nsample_slice.save_jpg('test.jpg', [dicom_windows.liver, dicom_windows.custom])\nshow_image(Image.open('test.jpg'), ax=axs[0], figsize=(8, 6))","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:09:20.177431Z","iopub.execute_input":"2023-08-27T12:09:20.178217Z","iopub.status.idle":"2023-08-27T12:09:20.451537Z","shell.execute_reply.started":"2023-08-27T12:09:20.178168Z","shell.execute_reply":"2023-08-27T12:09:20.45057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nGENERATE_JPG_FILES = True\n\nif (GENERATE_JPG_FILES) :\n    \n    path = Path(\".\")\n\n    os.makedirs('train_images',exist_ok=True)\n    os.makedirs('train_masks',exist_ok=True)\n\n    for ii in tqdm(range(0,len(df_files),3)): # take 1/3 nii files for training\n        curr_ct        = read_nii(df_files.loc[ii,'dirname']+\"/\"+df_files.loc[ii,'filename'])\n        curr_mask      = read_nii(df_files.loc[ii,'mask_dirname']+\"/\"+df_files.loc[ii,'mask_filename'])\n        curr_file_name = str(df_files.loc[ii,'filename']).split('.')[0]\n        curr_dim       = curr_ct.shape[2] # 512, 512, curr_dim\n\n        for curr_slice in range(0,curr_dim,2): # export every 2nd slice for training\n            data = tensor(curr_ct[...,curr_slice].astype(np.float32))\n            mask = tensor(curr_mask[...,curr_slice].astype(np.float32))\n            data.save_jpg(f\"train_images/{curr_file_name}_slice_{curr_slice}.jpg\", [dicom_windows.liver,dicom_windows.custom])\n            mask.save_jpg(f\"train_masks/{curr_file_name}_slice_{curr_slice}_mask.jpg\", [dicom_windows.liver,dicom_windows.custom])\nelse:\n    path = Path(\"../input/liver-segmentation-with-fastai-v2\") # read jpg from saved kernel output","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:09:26.069883Z","iopub.execute_input":"2023-08-27T12:09:26.070169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a meta file for nii files processing\nfile_list = []\nmask_list = []\nfor dirname, _, filenames in os.walk('/kaggle/working/train_images'):\n    for filename in filenames:\n        file_list.append(filename) \n\nfor dirname, _, filenames in os.walk('/kaggle/working/train_masks'):\n    for filename in filenames:\n        mask_list.append(filename) \n\nfiles = pd.DataFrame({\"train\": file_list, \"mask\": mask_list}) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = []\nfor i in range(len(files)):\n    root = \"/kaggle/working/train_images\"\n    path = os.path.join(root, files[\"train\"][i])\n    filename.append(path)","metadata":{"execution":{"iopub.status.busy":"2023-03-06T11:31:51.632877Z","iopub.execute_input":"2023-03-06T11:31:51.633144Z","iopub.status.idle":"2023-03-06T11:31:51.71317Z","shell.execute_reply.started":"2023-03-06T11:31:51.63311Z","shell.execute_reply":"2023-03-06T11:31:51.712417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = []\nfor i in range(len(files)):\n    root = \"/kaggle/working/train_masks\"\n    path = os.path.join(root, files[\"train\"][i])\n    mask.append(path)","metadata":{"execution":{"iopub.status.busy":"2023-03-06T11:31:51.714283Z","iopub.execute_input":"2023-03-06T11:31:51.714602Z","iopub.status.idle":"2023-03-06T11:31:51.792648Z","shell.execute_reply.started":"2023-03-06T11:31:51.714567Z","shell.execute_reply":"2023-03-06T11:31:51.792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data={\"filename\": filename, 'mask' : mask})","metadata":{"execution":{"iopub.status.busy":"2023-03-06T11:31:51.793924Z","iopub.execute_input":"2023-03-06T11:31:51.794175Z","iopub.status.idle":"2023-03-06T11:31:51.799674Z","shell.execute_reply.started":"2023-03-06T11:31:51.794142Z","shell.execute_reply":"2023-03-06T11:31:51.798736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['mask'] = df['mask'].str.split(\".\").str[0] + \"_mask.jpg\"","metadata":{"execution":{"iopub.status.busy":"2023-03-06T11:31:51.801174Z","iopub.execute_input":"2023-03-06T11:31:51.80143Z","iopub.status.idle":"2023-03-06T11:31:51.830566Z","shell.execute_reply.started":"2023-03-06T11:31:51.801397Z","shell.execute_reply":"2023-03-06T11:31:51.829886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\nimage= cv2.imread(df['mask'][5])\nprint(image.shape)\nplt.imshow(image)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-06T11:33:36.500038Z","iopub.execute_input":"2023-03-06T11:33:36.500437Z","iopub.status.idle":"2023-03-06T11:33:36.707569Z","shell.execute_reply.started":"2023-03-06T11:33:36.500406Z","shell.execute_reply":"2023-03-06T11:33:36.706837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df,test_size = 0.1, random_state = 42)\ndf_train, df_val = train_test_split(df_train,test_size = 0.2, random_state = 42)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-06T11:31:52.072034Z","iopub.execute_input":"2023-03-06T11:31:52.072297Z","iopub.status.idle":"2023-03-06T11:31:52.087204Z","shell.execute_reply.started":"2023-03-06T11:31:52.072262Z","shell.execute_reply":"2023-03-06T11:31:52.086697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy as np \nimport os\nimport glob\nimport skimage.io as io\nimport skimage.transform as trans\nimport sys\n# from mode.config import *\nnp.set_printoptions(threshold=sys.maxsize, precision=5, suppress=True)\n\ntumor = [120,0,0]\nliver = [0,255,0]\nUnlabelled = [0,0,0]\n\nCOLOR_DICT = np.array([ tumor, liver, Unlabelled])\nclass_name = [ 'tumor', 'liver', 'None']  # You must define by yourself\n\ncolor = 'grayscale'\n\nnum_classes = 3 # include cat, dog and None.\n# num_of_test_img = arg.img_num\n\ntest_img_size = 256 * 256\n\nimg_size = (256,256)\n\n\n\ndef adjustData(img,mask,flag_multi_class,num_class):\n    if(flag_multi_class):\n        img = img / 255.\n        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n        mask[(mask!=0.)&(mask!=255.)&(mask!=128.)] = 0.\n        new_mask = np.zeros(mask.shape + (num_class,))\n        new_mask[mask == 255.,   0] = 1\n        new_mask[mask == 128.,   1] = 1\n        new_mask[mask == 0.,   2] = 1\n        mask = new_mask\n\n    elif(np.max(img) > 1):\n        img = img / 255.\n        mask = mask /255.\n        mask[mask > 0.5] = 1\n        mask[mask <= 0.5] = 0\n    return (img,mask)\n\n\n\ndef trainGenerator( batch_size, dataframe, aug_dict, image_color_mode = \"grayscale\",\n                    mask_color_mode = \"grayscale\", image_save_prefix  = \"image\", mask_save_prefix  = \"mask\",\n                    flag_multi_class = True, num_class = num_classes , save_to_dir = None, target_size = img_size, seed = 1):\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    image_generator = image_datagen.flow_from_dataframe(\n        dataframe,\n        x_col = \"filename\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n    mask_generator = mask_datagen.flow_from_dataframe(\n        dataframe,\n        x_col = \"mask\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n#     print('classes:',image_generator.class_indices, mask_generator.class_indices)\n    train_generator = zip(image_generator, mask_generator)\n    for (img,mask) in train_generator:\n        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n        yield (img,mask)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-06T11:31:52.088493Z","iopub.execute_input":"2023-03-06T11:31:52.088908Z","iopub.status.idle":"2023-03-06T11:31:57.954603Z","shell.execute_reply.started":"2023-03-06T11:31:52.088872Z","shell.execute_reply":"2023-03-06T11:31:57.953841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\n# from keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras import backend as keras\n# from mode.config import *\n# from tensorflow.contrib.opt import AdamWOptimizer\nfrom tensorflow.python.keras.optimizers import TFOptimizer\nfrom tensorflow.keras import backend as K\nfrom keras.models import Model\n\nimg_size = (256,256,1) # 256 * 256 grayscale img with 1 channel\n\ndr_rate = 0.6 # never mind\nleakyrelu_alpha = 0.3\n\ndef unet(pretrained_weights = None,input_size = img_size):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = LeakyReLU(alpha=leakyrelu_alpha)(conv1)\n    #conv1 = Dropout(dr_rate)(conv1) ###\n    conv1 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    conv1 = BatchNormalization()(conv1)    \n    conv1 = LeakyReLU(alpha=leakyrelu_alpha)(conv1)\n    #conv1 = Dropout(dr_rate)(conv1) ###\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    #pool1 = Dropout(dr_rate)(pool1) ### \n    \n    conv2 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = LeakyReLU(alpha=leakyrelu_alpha)(conv2)\n    #conv2 = Dropout(dr_rate)(conv2)###\n    conv2 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = LeakyReLU(alpha=leakyrelu_alpha)(conv2)    \n    #conv2 = Dropout(dr_rate)(conv2)###    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    \n    conv3 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = LeakyReLU(alpha=leakyrelu_alpha)(conv3)\n    #conv3 = Dropout(dr_rate)(conv3) ###\n    conv3 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = LeakyReLU(alpha=leakyrelu_alpha)(conv3)\n    #conv3 = Dropout(dr_rate)(conv3) ###\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    \n    conv4 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = LeakyReLU(alpha=leakyrelu_alpha)(conv4)    \n    #conv4 = Dropout(dr_rate)(conv4) ###\n    conv4 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = LeakyReLU(alpha=leakyrelu_alpha)(conv4)\n    drop4 = Dropout(dr_rate)(conv4) ###\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)    \n\n    conv5 = Conv2D(1024, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = BatchNormalization()(conv5)    \n    conv5 = LeakyReLU(alpha=leakyrelu_alpha)(conv5)\n    #conv5 = Dropout(dr_rate)(conv5) ###\n    conv5 = Conv2D(1024, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    conv5 = BatchNormalization()(conv5)\n    drop5 = LeakyReLU(alpha=leakyrelu_alpha)(conv5)\n    #drop5 = Dropout(dr_rate)(conv5) ###\n\n    up6 = Conv2D(512, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    up6 = LeakyReLU(alpha=leakyrelu_alpha)(up6)\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = LeakyReLU(alpha=leakyrelu_alpha)(conv6)\n    #conv6 = Dropout(dr_rate)(conv6) ###\n    conv6 = Conv2D(512, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = LeakyReLU(alpha=leakyrelu_alpha)(conv6)    \n    #conv6 = Dropout(dr_rate)(conv6) ###   \n\n    up7 = Conv2D(256, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    up7 = BatchNormalization()(up7)    \n    up7 = LeakyReLU(alpha=leakyrelu_alpha)(up7)\n    up7 = Dropout(dr_rate)(up7) ###\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = BatchNormalization()(conv7)    \n    conv7 = LeakyReLU(alpha=leakyrelu_alpha)(conv7)    \n    #conv7 = Dropout(dr_rate)(conv7) ###\n    conv7 = Conv2D(256, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv7)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = LeakyReLU(alpha=leakyrelu_alpha)(conv7)\n    #conv7 = Dropout(dr_rate)(conv7) ###   \n\n    up8 = Conv2D(128, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    up8 = BatchNormalization()(up8)\n    up8 = LeakyReLU(alpha=0.3)(up8)\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = BatchNormalization()(conv8)\n    conv8 = LeakyReLU(alpha=0.3)(conv8)\n    #conv8 = Dropout(dr_rate)(conv8) ###\n    conv8 = Conv2D(128, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv8)\n    conv8 = BatchNormalization()(conv8)    \n    conv8 = LeakyReLU(alpha=0.3)(conv8)    \n    #conv8 = Dropout(dr_rate)(conv8) ###    \n\n    up9 = Conv2D(64, 2, activation = None, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    up9 = BatchNormalization()(up9)\n    up9 = LeakyReLU(alpha=leakyrelu_alpha)(up9)\n    up9 = Dropout(dr_rate)(up9) ###\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = BatchNormalization()(conv9)\n    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n    #conv9 = Dropout(dr_rate)(conv9) ###\n    conv9 = Conv2D(64, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = BatchNormalization()(conv9)    \n    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n    #conv9 = Dropout(dr_rate)(conv9) ###\n    conv9 = Conv2D(2, 3, activation = None, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = BatchNormalization()(conv9)\n    conv9 = LeakyReLU(alpha=leakyrelu_alpha)(conv9)    \n    #conv9 = Dropout(dr_rate)(conv9) ###\n\n    conv10 = Conv2D(3, 1, activation = 'softmax')(conv9)\n    model = Model(inputs = inputs, outputs = conv10)   \n    model.compile(optimizer = Adam(lr = 3e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    \n    #model.summary()\n\n    if(pretrained_weights):\n    \tmodel.load_weights(pretrained_weights)\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-03-06T11:34:46.778021Z","iopub.execute_input":"2023-03-06T11:34:46.778589Z","iopub.status.idle":"2023-03-06T11:34:46.809583Z","shell.execute_reply.started":"2023-03-06T11:34:46.778541Z","shell.execute_reply":"2023-03-06T11:34:46.808855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport os.path\n# from model import *\n# from data import *\nfrom keras.models import load_model\nfrom keras.callbacks import History\nimport tensorflow as tf\nimport matplotlib.pyplot as plt \nfrom keras import backend as K\n# from mode.config import *\n# from csvrecord import * \nfrom pathlib import Path\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\nfrom keras.layers import LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\n\ndata_gen_args = dict()\n\nmyGene = trainGenerator(12, df_val, data_gen_args, save_to_dir = None)\n\n\nmodel = unet()\n# model_checkpoint = ModelCheckpoint(model_name, monitor='loss',verbose=1, save_best_only=True)\nhistory = model.fit_generator(myGene, steps_per_epoch=len(df_val)/32, epochs=5)","metadata":{"execution":{"iopub.status.busy":"2023-03-06T11:44:09.02897Z","iopub.execute_input":"2023-03-06T11:44:09.029724Z","iopub.status.idle":"2023-03-06T11:46:24.907095Z","shell.execute_reply.started":"2023-03-06T11:44:09.029688Z","shell.execute_reply":"2023-03-06T11:46:24.906326Z"},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}